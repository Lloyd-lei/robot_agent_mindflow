#!/usr/bin/env python
"""
Ollama é…ç½®æµ‹è¯•è„šæœ¬

åŠŸèƒ½ï¼š
1. æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ
2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
3. æµ‹è¯•åŸºç¡€å¯¹è¯åŠŸèƒ½
4. æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½
"""

import sys
import requests
from colorama import Fore, Style, init

init(autoreset=True)

def check_ollama_service():
    """æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦è¿è¡Œ"""
    print(f"\n{Fore.CYAN}ã€æ­¥éª¤ 1ã€‘æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€{Style.RESET_ALL}")
    
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print(f"{Fore.GREEN}âœ… Ollama æœåŠ¡æ­£åœ¨è¿è¡Œï¼{Style.RESET_ALL}")
            return True
        else:
            print(f"{Fore.RED}âŒ Ollama æœåŠ¡çŠ¶æ€å¼‚å¸¸ï¼ˆçŠ¶æ€ç ï¼š{response.status_code}ï¼‰{Style.RESET_ALL}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"{Fore.RED}âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}ğŸ’¡ è¯·è¿è¡Œ: ollama serve{Style.RESET_ALL}")
        return False
    except Exception as e:
        print(f"{Fore.RED}âŒ æ£€æŸ¥æœåŠ¡æ—¶å‡ºé”™: {e}{Style.RESET_ALL}")
        return False


def check_model_exists(model_name="qwen2.5:7b"):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½"""
    print(f"\n{Fore.CYAN}ã€æ­¥éª¤ 2ã€‘æ£€æŸ¥æ¨¡å‹ {model_name} æ˜¯å¦å­˜åœ¨{Style.RESET_ALL}")
    
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            model_names = [m["name"] for m in models]
            
            if model_name in model_names:
                print(f"{Fore.GREEN}âœ… æ¨¡å‹ {model_name} å·²ä¸‹è½½ï¼{Style.RESET_ALL}")
                return True
            else:
                print(f"{Fore.RED}âŒ æ¨¡å‹ {model_name} æœªæ‰¾åˆ°{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}ğŸ“‹ å·²ä¸‹è½½çš„æ¨¡å‹: {', '.join(model_names) if model_names else '(æ— )'}{Style.RESET_ALL}")
                print(f"{Fore.YELLOW}ğŸ’¡ è¯·è¿è¡Œ: ollama pull {model_name}{Style.RESET_ALL}")
                return False
        else:
            print(f"{Fore.RED}âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥{Style.RESET_ALL}")
            return False
    except Exception as e:
        print(f"{Fore.RED}âŒ æ£€æŸ¥æ¨¡å‹æ—¶å‡ºé”™: {e}{Style.RESET_ALL}")
        return False


def test_basic_chat():
    """æµ‹è¯•åŸºç¡€å¯¹è¯åŠŸèƒ½"""
    print(f"\n{Fore.CYAN}ã€æ­¥éª¤ 3ã€‘æµ‹è¯•åŸºç¡€å¯¹è¯{Style.RESET_ALL}")
    
    try:
        from openai import OpenAI
        import config
        
        print(f"ğŸ“Š ä½¿ç”¨æ¨¡å‹: {config.LLM_MODEL}")
        print(f"ğŸ“Š ä½¿ç”¨åœ°å€: {config.LLM_BASE_URL}")
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        if config.LLM_BASE_URL:
            client = OpenAI(api_key="ollama", base_url=config.LLM_BASE_URL)
        else:
            client = OpenAI(api_key=config.LLM_API_KEY)
        
        # æµ‹è¯•å¯¹è¯
        print(f"{Fore.YELLOW}â³ æ­£åœ¨æµ‹è¯•åŸºç¡€å¯¹è¯ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿï¼‰...{Style.RESET_ALL}")
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
            ],
            temperature=0
        )
        
        answer = response.choices[0].message.content
        print(f"{Fore.GREEN}âœ… åŸºç¡€å¯¹è¯æµ‹è¯•æˆåŠŸï¼{Style.RESET_ALL}")
        print(f"{Fore.CYAN}ğŸ¤– æ¨¡å‹å›å¤: {answer}{Style.RESET_ALL}")
        return True
        
    except Exception as e:
        print(f"{Fore.RED}âŒ åŸºç¡€å¯¹è¯æµ‹è¯•å¤±è´¥: {e}{Style.RESET_ALL}")
        return False


def test_function_calling():
    """æµ‹è¯•å·¥å…·è°ƒç”¨åŠŸèƒ½"""
    print(f"\n{Fore.CYAN}ã€æ­¥éª¤ 4ã€‘æµ‹è¯•å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰{Style.RESET_ALL}")
    
    try:
        from openai import OpenAI
        import config
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        if config.LLM_BASE_URL:
            client = OpenAI(api_key="ollama", base_url=config.LLM_BASE_URL)
        else:
            client = OpenAI(api_key=config.LLM_API_KEY)
        
        # å®šä¹‰ä¸€ä¸ªç®€å•çš„å·¥å…·
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_current_time",
                    "description": "è·å–å½“å‰æ—¶é—´",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                        "required": []
                    }
                }
            }
        ]
        
        # æµ‹è¯•å·¥å…·è°ƒç”¨
        print(f"{Fore.YELLOW}â³ æ­£åœ¨æµ‹è¯•å·¥å…·è°ƒç”¨...{Style.RESET_ALL}")
        
        response = client.chat.completions.create(
            model=config.LLM_MODEL,
            messages=[
                {"role": "user", "content": "ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ"}
            ],
            tools=tools,
            tool_choice="auto"
        )
        
        # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†å·¥å…·
        if response.choices[0].message.tool_calls:
            tool_call = response.choices[0].message.tool_calls[0]
            print(f"{Fore.GREEN}âœ… å·¥å…·è°ƒç”¨æµ‹è¯•æˆåŠŸï¼{Style.RESET_ALL}")
            print(f"{Fore.CYAN}ğŸ”§ è°ƒç”¨çš„å·¥å…·: {tool_call.function.name}{Style.RESET_ALL}")
            return True
        else:
            print(f"{Fore.YELLOW}âš ï¸  æ¨¡å‹æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼ˆå¯èƒ½ä¸æ”¯æŒ Function Callingï¼‰{Style.RESET_ALL}")
            print(f"{Fore.YELLOW}ğŸ’¡ å»ºè®®ï¼šéƒ¨åˆ† Ollama æ¨¡å‹å¯èƒ½ä¸å®Œå…¨æ”¯æŒå·¥å…·è°ƒç”¨ï¼Œä½†åŸºç¡€å¯¹è¯åŠŸèƒ½æ­£å¸¸{Style.RESET_ALL}")
            return False
        
    except Exception as e:
        print(f"{Fore.RED}âŒ å·¥å…·è°ƒç”¨æµ‹è¯•å¤±è´¥: {e}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}ğŸ’¡ è¯´æ˜ï¼šéƒ¨åˆ† Ollama æ¨¡å‹å¯èƒ½ä¸æ”¯æŒ OpenAI çš„ Function Calling æ ¼å¼{Style.RESET_ALL}")
        return False


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print(f"\n{Fore.GREEN}{'='*60}")
    print(f"  ğŸ¦™ Ollama é…ç½®æµ‹è¯•å·¥å…·")
    print(f"{'='*60}{Style.RESET_ALL}\n")
    
    # æ­¥éª¤ 1: æ£€æŸ¥æœåŠ¡
    if not check_ollama_service():
        print(f"\n{Fore.RED}âŒ æµ‹è¯•ç»ˆæ­¢ï¼šOllama æœåŠ¡æœªè¿è¡Œ{Style.RESET_ALL}")
        return False
    
    # æ­¥éª¤ 2: æ£€æŸ¥æ¨¡å‹
    if not check_model_exists():
        print(f"\n{Fore.RED}âŒ æµ‹è¯•ç»ˆæ­¢ï¼šæ¨¡å‹æœªä¸‹è½½{Style.RESET_ALL}")
        return False
    
    # æ­¥éª¤ 3: æµ‹è¯•åŸºç¡€å¯¹è¯
    if not test_basic_chat():
        print(f"\n{Fore.RED}âŒ æµ‹è¯•ç»ˆæ­¢ï¼šåŸºç¡€å¯¹è¯å¤±è´¥{Style.RESET_ALL}")
        return False
    
    # æ­¥éª¤ 4: æµ‹è¯•å·¥å…·è°ƒç”¨ï¼ˆä¸å½±å“æ•´ä½“ç»“æœï¼‰
    test_function_calling()
    
    # æ€»ç»“
    print(f"\n{Fore.GREEN}{'='*60}")
    print(f"  âœ… Ollama é…ç½®æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*60}{Style.RESET_ALL}\n")
    
    print(f"{Fore.CYAN}ğŸ“ ä¸‹ä¸€æ­¥ï¼š{Style.RESET_ALL}")
    print(f"   python demo_hybrid.py streaming")
    
    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print(f"\n{Fore.YELLOW}âš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­{Style.RESET_ALL}")
        sys.exit(1)
    except Exception as e:
        print(f"\n{Fore.RED}âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}{Style.RESET_ALL}")
        sys.exit(1)

