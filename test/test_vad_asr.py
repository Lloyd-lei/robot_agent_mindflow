#!/usr/bin/env python3
"""
VAD + ASR ç‹¬ç«‹æµ‹è¯•ç¨‹åº
ç”¨äºè°ƒæ•™ VAD å‚æ•°å’Œæµ‹è¯• ASR å‡†ç¡®æ€§
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

import pyaudio
import numpy as np
import wave
import time
from datetime import datetime
from colorama import Fore, Style, init
from asr_interface import OpenAIASR
import config

init(autoreset=True)


class SimpleVAD:
    """ç®€åŒ–çš„ VADï¼ˆåŸºäºèƒ½é‡æ£€æµ‹ï¼‰"""
    
    def __init__(
        self,
        energy_threshold: float = 1100.0,
        silence_duration_ms: int = 900,
        frame_duration_ms: int = 30,
        sample_rate: int = 16000
    ):
        self.energy_threshold = energy_threshold
        self.silence_duration_ms = silence_duration_ms
        self.frame_duration_ms = frame_duration_ms
        self.sample_rate = sample_rate
        
        # è®¡ç®—éœ€è¦å¤šå°‘å¸§æ‰ç®—é™éŸ³
        self.num_silence_frames = int(silence_duration_ms / frame_duration_ms)
        
        print(f"{Fore.GREEN}âœ… VAD åˆå§‹åŒ–:")
        print(f"   - èƒ½é‡é˜ˆå€¼: {energy_threshold}")
        print(f"   - é™éŸ³åˆ¤å®š: {silence_duration_ms}ms ({self.num_silence_frames}å¸§)")
        print(f"   - é‡‡æ ·ç‡: {sample_rate}Hz\n")
    
    def is_speech(self, audio_data: bytes) -> tuple[bool, float]:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºè¯­éŸ³
        
        Returns:
            (is_speech, energy): æ˜¯å¦ä¸ºè¯­éŸ³ï¼Œèƒ½é‡å€¼
        """
        samples = np.frombuffer(audio_data, dtype=np.int16)
        energy = np.sqrt(np.mean(samples.astype(np.float32) ** 2))
        
        is_speech = energy > self.energy_threshold
        
        return is_speech, energy


class VoiceRecorder:
    """è¯­éŸ³å½•éŸ³å™¨ï¼ˆå¸¦ VADï¼‰"""
    
    def __init__(
        self,
        vad: SimpleVAD,
        sample_rate: int = 16000,
        channels: int = 1,
        chunk_size: int = 480  # 30ms @ 16kHz
    ):
        self.vad = vad
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk_size = chunk_size
        
        self.audio = pyaudio.PyAudio()
        self.stream = None
    
    def record_until_silence(self, max_duration: float = 30.0) -> tuple[bytes, dict]:
        """
        å½•éŸ³ç›´åˆ°æ£€æµ‹åˆ°é™éŸ³
        
        Returns:
            (audio_data, stats): éŸ³é¢‘æ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯
        """
        print(f"{Fore.YELLOW}ğŸ¤ æ­£åœ¨ç›‘å¬...ï¼ˆè¯·è¯´è¯ï¼Œè¯´å®Œåä¿æŒå®‰é™{self.vad.silence_duration_ms}msï¼‰\n")
        
        # æ‰“å¼€éŸ³é¢‘æµ
        try:
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=self.channels,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
        except Exception as e:
            print(f"{Fore.RED}âŒ æ— æ³•æ‰“å¼€éŸ³é¢‘æµ: {e}")
            return b'', {}
        
        audio_frames = []
        silence_frames = 0
        speech_started = False
        start_time = time.time()
        
        max_energy = 0
        min_energy = float('inf')
        energies = []
        
        try:
            while True:
                # æ£€æŸ¥è¶…æ—¶
                if time.time() - start_time > max_duration:
                    print(f"\n{Fore.YELLOW}â° è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿ {max_duration}ç§’")
                    break
                
                # è¯»å–éŸ³é¢‘å¸§
                try:
                    frame = self.stream.read(self.chunk_size, exception_on_overflow=False)
                except Exception as e:
                    print(f"\n{Fore.RED}âŒ è¯»å–éŸ³é¢‘å¤±è´¥: {e}")
                    break
                
                # VAD æ£€æµ‹
                is_speech, energy = self.vad.is_speech(frame)
                
                energies.append(energy)
                max_energy = max(max_energy, energy)
                min_energy = min(min_energy, energy)
                
                # æ˜¾ç¤ºèƒ½é‡æ¡
                bar_length = int(min(energy / 50, 50))
                bar = "â–ˆ" * bar_length
                
                if is_speech:
                    color = Fore.GREEN
                    status = "ğŸ—£ï¸ æ£€æµ‹åˆ°è¯­éŸ³"
                else:
                    color = Fore.YELLOW
                    status = "ğŸ”‡ é™éŸ³"
                
                print(f"\r{color}èƒ½é‡: {energy:7.1f} |{bar:<50}| {status}", end='', flush=True)
                
                # çŠ¶æ€æœº
                if not speech_started:
                    # ç­‰å¾…è¯­éŸ³å¼€å§‹
                    if is_speech:
                        speech_started = True
                        audio_frames.append(frame)
                        silence_frames = 0
                        print(f"\n{Fore.GREEN}âœ… å¼€å§‹å½•éŸ³...\n")
                else:
                    # å·²å¼€å§‹å½•éŸ³
                    audio_frames.append(frame)
                    
                    if is_speech:
                        silence_frames = 0
                    else:
                        silence_frames += 1
                        
                        # æ£€æµ‹åˆ°è¶³å¤Ÿé•¿çš„é™éŸ³
                        if silence_frames >= self.vad.num_silence_frames:
                            print(f"\n{Fore.GREEN}âœ… æ£€æµ‹åˆ°é™éŸ³ï¼Œåœæ­¢å½•éŸ³")
                            break
        
        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}âš ï¸  ç”¨æˆ·ä¸­æ–­")
        
        finally:
            # å…³é—­éŸ³é¢‘æµ
            if self.stream:
                self.stream.stop_stream()
                self.stream.close()
        
        # åˆå¹¶éŸ³é¢‘æ•°æ®
        audio_data = b''.join(audio_frames)
        duration = len(audio_data) / (self.sample_rate * 2)  # 2 bytes per sample
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'duration': duration,
            'frames': len(audio_frames),
            'min_energy': min_energy,
            'max_energy': max_energy,
            'avg_energy': np.mean(energies) if energies else 0,
            'speech_started': speech_started
        }
        
        print(f"\n{Fore.CYAN}ğŸ“Š å½•éŸ³ç»Ÿè®¡:")
        print(f"   - æ—¶é•¿: {duration:.2f}ç§’")
        print(f"   - å¸§æ•°: {len(audio_frames)}")
        print(f"   - èƒ½é‡èŒƒå›´: {min_energy:.1f} - {max_energy:.1f}")
        print(f"   - å¹³å‡èƒ½é‡: {stats['avg_energy']:.1f}\n")
        
        return audio_data, stats
    
    def save_wav(self, audio_data: bytes, filename: str):
        """ä¿å­˜ä¸º WAV æ–‡ä»¶"""
        try:
            with wave.open(filename, 'wb') as wf:
                wf.setnchannels(self.channels)
                wf.setsampwidth(2)  # 16-bit
                wf.setframerate(self.sample_rate)
                wf.writeframes(audio_data)
            
            print(f"{Fore.GREEN}ğŸ’¾ å·²ä¿å­˜: {filename}\n")
        except Exception as e:
            print(f"{Fore.RED}âŒ ä¿å­˜å¤±è´¥: {e}\n")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.stream:
            self.stream.close()
        
        if self.audio:
            self.audio.terminate()
        
        print(f"{Fore.GREEN}âœ… å½•éŸ³å™¨èµ„æºå·²é‡Šæ”¾\n")


def test_vad_asr():
    """æµ‹è¯• VAD + ASR"""
    print("\n" + "=" * 80)
    print(Fore.CYAN + Style.BRIGHT + "ğŸ¤ VAD + ASR æµ‹è¯•ç¨‹åº")
    print("=" * 80 + "\n")
    
    # é…ç½®å‚æ•°
    print(f"{Fore.CYAN}ğŸ“Š å½“å‰é…ç½®ï¼š")
    print(f"   - èƒ½é‡é˜ˆå€¼: {Fore.WHITE}1100.0 (AirPods Pro)")
    print(f"   - é™éŸ³åˆ¤å®š: {Fore.WHITE}900ms")
    print(f"   - é‡‡æ ·ç‡: {Fore.WHITE}16000 Hz")
    print(f"   - ASR: {Fore.WHITE}OpenAI Whisper-1\n")
    
    # åˆå§‹åŒ– VAD
    vad = SimpleVAD(
        energy_threshold=1100.0,  # AirPods Pro
        silence_duration_ms=900,
        sample_rate=16000
    )
    
    # åˆå§‹åŒ–å½•éŸ³å™¨
    recorder = VoiceRecorder(vad, sample_rate=16000)
    
    # åˆå§‹åŒ– ASR
    print(f"{Fore.CYAN}â³ åˆå§‹åŒ– ASR...")
    asr = OpenAIASR(
        api_key=config.OPENAI_API_KEY,
        model="whisper-1"
    )
    print(f"{Fore.GREEN}âœ… ASR åˆå§‹åŒ–å®Œæˆ\n")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = Path("temp_audio")
    temp_dir.mkdir(exist_ok=True)
    
    round_num = 0
    
    try:
        while True:
            round_num += 1
            print(f"\n{Fore.MAGENTA}{'='*80}")
            print(f"{Fore.MAGENTA}ğŸ”„ æµ‹è¯•è½®æ¬¡ {round_num}")
            print(f"{Fore.MAGENTA}{'='*80}\n")
            
            # 1. å½•éŸ³ï¼ˆå¸¦ VADï¼‰
            audio_data, stats = recorder.record_until_silence(max_duration=30.0)
            
            if not audio_data or not stats.get('speech_started'):
                print(f"{Fore.RED}âš ï¸  æœªæ£€æµ‹åˆ°æœ‰æ•ˆè¯­éŸ³\n")
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­
                choice = input(f"{Fore.YELLOW}ç»§ç»­æµ‹è¯•ï¼Ÿ(y/n/adjust): {Style.RESET_ALL}").strip().lower()
                
                if choice == 'n':
                    break
                elif choice == 'adjust':
                    # è°ƒæ•´é˜ˆå€¼
                    new_threshold = input(f"{Fore.YELLOW}æ–°çš„èƒ½é‡é˜ˆå€¼ï¼ˆå½“å‰{vad.energy_threshold}ï¼‰: {Style.RESET_ALL}").strip()
                    try:
                        vad.energy_threshold = float(new_threshold)
                        print(f"{Fore.GREEN}âœ… é˜ˆå€¼å·²æ›´æ–°: {vad.energy_threshold}\n")
                    except ValueError:
                        print(f"{Fore.RED}âŒ æ— æ•ˆçš„æ•°å€¼\n")
                
                continue
            
            # 2. ä¿å­˜éŸ³é¢‘ï¼ˆå¯é€‰ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_file = temp_dir / f"recording_{timestamp}.wav"
            recorder.save_wav(audio_data, str(audio_file))
            
            # 3. ASR è¯†åˆ«
            print(f"{Fore.CYAN}ğŸ”„ æ­£åœ¨è¯†åˆ«...\n")
            
            asr_start = time.time()
            result = asr.transcribe(str(audio_file))
            asr_time = time.time() - asr_start
            
            # 4. æ˜¾ç¤ºç»“æœ
            print(f"{Fore.GREEN}{'='*80}")
            print(f"{Fore.GREEN}ğŸ“ è¯†åˆ«ç»“æœ")
            print(f"{Fore.GREEN}{'='*80}\n")
            
            if result.text:
                print(f"{Fore.CYAN}æ–‡æœ¬: {Fore.WHITE}{result.text}")
                print(f"{Fore.CYAN}è¯­è¨€: {Fore.WHITE}{result.language}")
                print(f"{Fore.CYAN}ASR è€—æ—¶: {Fore.WHITE}{asr_time:.2f}ç§’")
                
                # è®¡ç®—å¤„ç†é€Ÿåº¦
                speed_ratio = result.duration / asr_time if asr_time > 0 else 0
                print(f"{Fore.CYAN}å¤„ç†é€Ÿåº¦: {Fore.GREEN}{speed_ratio:.1f}x å®æ—¶")
                
                # è®¡ç®—æˆæœ¬ (Whisper: $0.006/åˆ†é’Ÿ)
                cost = result.duration / 60 * 0.006
                print(f"{Fore.CYAN}æˆæœ¬: {Fore.WHITE}${cost:.4f} (çº¦ Â¥{cost * 7:.4f})")
            else:
                print(f"{Fore.RED}âŒ ASR è¯†åˆ«å¤±è´¥")
                if hasattr(result, 'error'):
                    print(f"{Fore.RED}   é”™è¯¯: {result.error}")
            
            print(f"\n{Fore.GREEN}{'='*80}\n")
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            choice = input(f"{Fore.YELLOW}ç»§ç»­æµ‹è¯•ï¼Ÿ(y/n/adjust): {Style.RESET_ALL}").strip().lower()
            
            if choice == 'n':
                break
            elif choice == 'adjust':
                # è°ƒæ•´é˜ˆå€¼
                print(f"\n{Fore.CYAN}å½“å‰å‚æ•°:")
                print(f"   - èƒ½é‡é˜ˆå€¼: {vad.energy_threshold}")
                print(f"   - é™éŸ³åˆ¤å®š: {vad.silence_duration_ms}ms")
                
                new_threshold = input(f"{Fore.YELLOW}æ–°çš„èƒ½é‡é˜ˆå€¼ï¼ˆç›´æ¥å›è½¦è·³è¿‡ï¼‰: {Style.RESET_ALL}").strip()
                if new_threshold:
                    try:
                        vad.energy_threshold = float(new_threshold)
                        print(f"{Fore.GREEN}âœ… é˜ˆå€¼å·²æ›´æ–°: {vad.energy_threshold}")
                    except ValueError:
                        print(f"{Fore.RED}âŒ æ— æ•ˆçš„æ•°å€¼")
                
                new_silence = input(f"{Fore.YELLOW}æ–°çš„é™éŸ³æ—¶é•¿ï¼ˆmsï¼Œç›´æ¥å›è½¦è·³è¿‡ï¼‰: {Style.RESET_ALL}").strip()
                if new_silence:
                    try:
                        vad.silence_duration_ms = int(new_silence)
                        vad.num_silence_frames = int(vad.silence_duration_ms / vad.frame_duration_ms)
                        print(f"{Fore.GREEN}âœ… é™éŸ³æ—¶é•¿å·²æ›´æ–°: {vad.silence_duration_ms}ms")
                    except ValueError:
                        print(f"{Fore.RED}âŒ æ— æ•ˆçš„æ•°å€¼")
                
                print()
    
    except KeyboardInterrupt:
        print(f"\n\n{Fore.YELLOW}âš ï¸  æµ‹è¯•ä¸­æ–­\n")
    
    finally:
        # æ¸…ç†èµ„æº
        print(f"{Fore.CYAN}ğŸ§¹ æ¸…ç†èµ„æº...\n")
        recorder.cleanup()
        
        print(f"{Fore.GREEN}{'='*80}")
        print(f"{Fore.GREEN}ğŸ“Š æµ‹è¯•æ€»ç»“")
        print(f"{Fore.GREEN}{'='*80}\n")
        print(f"{Fore.CYAN}æµ‹è¯•è½®æ¬¡: {Fore.WHITE}{round_num}")
        print(f"{Fore.CYAN}ä¸´æ—¶æ–‡ä»¶: {Fore.WHITE}{temp_dir}/")
        print(f"\n{Fore.GREEN}âœ… æµ‹è¯•å®Œæˆ\n")


if __name__ == "__main__":
    test_vad_asr()

