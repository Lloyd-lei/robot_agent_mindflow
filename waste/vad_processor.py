"""
VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰å¤„ç†å™¨
åŸºäºç®€å•çš„èƒ½é‡æ£€æµ‹å®ç°ï¼ˆæ— éœ€å¤–éƒ¨ä¾èµ–ï¼‰
ä¼˜åŒ–ç‰ˆæœ¬ï¼šé™ä½å»¶è¿Ÿï¼Œæå‡å“åº”é€Ÿåº¦
"""
import numpy as np
import collections
import struct
from typing import Generator, Optional, Tuple
from logger_config import get_logger

logger = get_logger(__name__)


class VADProcessor:
    """
    VAD å¤„ç†å™¨ - æ£€æµ‹è¯­éŸ³æ´»åŠ¨ï¼Œå»é™¤é™éŸ³
    
    ç‰¹æ€§ï¼š
    - âœ… é›¶ä¾èµ–ï¼ˆåŸºäºèƒ½é‡æ£€æµ‹ï¼‰
    - âœ… å®æ—¶æ£€æµ‹è¯­éŸ³å¼€å§‹/ç»“æŸ
    - âœ… ä½å»¶è¿Ÿï¼ˆ<100msï¼‰
    - âœ… è‡ªé€‚åº”é˜ˆå€¼
    - âœ… å»é™¤é™éŸ³ï¼ˆèŠ‚çœ ASR æˆæœ¬ï¼‰
    
    åŸç†ï¼š
    1. è®¡ç®—éŸ³é¢‘å¸§çš„èƒ½é‡ï¼ˆæŒ¯å¹…ï¼‰
    2. ä¸é˜ˆå€¼æ¯”è¾ƒåˆ¤æ–­æ˜¯å¦ä¸ºè¯­éŸ³
    3. ä½¿ç”¨æ»‘åŠ¨çª—å£å¹³æ»‘åˆ¤æ–­
    4. æ£€æµ‹æŒç»­é™éŸ³åˆ¤å®šè¯­éŸ³ç»“æŸ
    """
    
    def __init__(
        self,
        sample_rate: int = 16000,
        frame_duration_ms: int = 30,
        energy_threshold: float = 300.0,
        silence_duration_ms: int = 900,
        pre_speech_padding_ms: int = 300,
        post_speech_padding_ms: int = 300,
        auto_adjust_threshold: bool = True
    ):
        """
        åˆå§‹åŒ– VAD
        
        Args:
            sample_rate: é‡‡æ ·ç‡
            frame_duration_ms: å¸§é•¿åº¦ï¼ˆæ¯«ç§’ï¼‰
            energy_threshold: èƒ½é‡é˜ˆå€¼ï¼ˆè‡ªåŠ¨è°ƒæ•´æ—¶ä½œä¸ºåˆå§‹å€¼ï¼‰
            silence_duration_ms: é™éŸ³æŒç»­å¤šä¹…åˆ¤å®šä¸ºç»“æŸ
            pre_speech_padding_ms: è¯­éŸ³å¼€å§‹å‰çš„å¡«å……æ—¶é•¿
            post_speech_padding_ms: è¯­éŸ³ç»“æŸåçš„å¡«å……æ—¶é•¿
            auto_adjust_threshold: æ˜¯å¦è‡ªåŠ¨è°ƒæ•´é˜ˆå€¼
        """
        self.sample_rate = sample_rate
        self.frame_duration_ms = frame_duration_ms
        self.energy_threshold = energy_threshold
        self.silence_duration_ms = silence_duration_ms
        self.pre_speech_padding_ms = pre_speech_padding_ms
        self.post_speech_padding_ms = post_speech_padding_ms
        self.auto_adjust_threshold = auto_adjust_threshold
        
        # è®¡ç®—å¸§å‚æ•°
        self.frame_size = int(sample_rate * frame_duration_ms / 1000)
        self.frame_bytes = self.frame_size * 2  # 2 bytes per sample (int16)
        
        # è®¡ç®—å¡«å……å’Œé™éŸ³å¸§æ•°
        self.num_pre_padding_frames = int(pre_speech_padding_ms / frame_duration_ms)
        self.num_post_padding_frames = int(post_speech_padding_ms / frame_duration_ms)
        self.num_silence_frames = int(silence_duration_ms / frame_duration_ms)
        
        # è‡ªé€‚åº”é˜ˆå€¼ç›¸å…³
        self.energy_history = collections.deque(maxlen=50)  # ä¿ç•™æœ€è¿‘50å¸§çš„èƒ½é‡
        self.noise_energy = energy_threshold  # ä¼°è®¡çš„å™ªéŸ³èƒ½é‡
        
        logger.info(f"âœ… VAD åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"   é‡‡æ ·ç‡: {sample_rate} Hz")
        logger.info(f"   å¸§é•¿åº¦: {frame_duration_ms} ms")
        logger.info(f"   èƒ½é‡é˜ˆå€¼: {energy_threshold:.1f}")
        logger.info(f"   é™éŸ³åˆ¤å®š: {silence_duration_ms} ms")
        logger.info(f"   è‡ªé€‚åº”é˜ˆå€¼: {'å¼€å¯' if auto_adjust_threshold else 'å…³é—­'}")
    
    def calculate_energy(self, frame: bytes) -> float:
        """
        è®¡ç®—éŸ³é¢‘å¸§çš„èƒ½é‡
        
        Args:
            frame: éŸ³é¢‘å¸§æ•°æ®ï¼ˆint16ï¼‰
        
        Returns:
            èƒ½é‡å€¼
        """
        if len(frame) != self.frame_bytes:
            return 0.0
        
        # è§£æä¸º int16 æ•°ç»„
        samples = np.frombuffer(frame, dtype=np.int16)
        
        # è®¡ç®— RMS èƒ½é‡
        energy = np.sqrt(np.mean(samples.astype(np.float32) ** 2))
        
        return float(energy)
    
    def is_speech(self, frame: bytes) -> bool:
        """
        åˆ¤æ–­å•å¸§æ˜¯å¦ä¸ºè¯­éŸ³
        
        Args:
            frame: éŸ³é¢‘å¸§
        
        Returns:
            True=è¯­éŸ³, False=é™éŸ³
        """
        energy = self.calculate_energy(frame)
        
        # è®°å½•èƒ½é‡å†å²ï¼ˆç”¨äºè‡ªé€‚åº”é˜ˆå€¼ï¼‰
        self.energy_history.append(energy)
        
        # è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´
        if self.auto_adjust_threshold and len(self.energy_history) >= 10:
            # ä½¿ç”¨å†å²èƒ½é‡çš„ä¸­ä½æ•°ä½œä¸ºå™ªéŸ³ä¼°è®¡
            sorted_energies = sorted(self.energy_history)
            self.noise_energy = sorted_energies[len(sorted_energies) // 4]  # 25% åˆ†ä½æ•°
            
            # åŠ¨æ€é˜ˆå€¼ = å™ªéŸ³èƒ½é‡ * 3
            dynamic_threshold = self.noise_energy * 3
            threshold = max(self.energy_threshold, dynamic_threshold)
        else:
            threshold = self.energy_threshold
        
        return energy > threshold
    
    def detect_speech_boundaries(
        self,
        audio_generator: Generator[bytes, None, None]
    ) -> Generator[Tuple[bytes, bool, bool], None, None]:
        """
        å®æ—¶æ£€æµ‹è¯­éŸ³è¾¹ç•Œï¼ˆæµå¼å¤„ç†ï¼‰
        
        Args:
            audio_generator: éŸ³é¢‘å¸§ç”Ÿæˆå™¨
        
        Yields:
            (frame, is_speech_start, is_speech_end)
        """
        ring_buffer = collections.deque(maxlen=self.num_pre_padding_frames)
        triggered = False
        silence_frames = 0
        
        for frame in audio_generator:
            if len(frame) != self.frame_bytes:
                continue
            
            is_speech = self.is_speech(frame)
            
            if not triggered:
                # æœªè§¦å‘çŠ¶æ€ï¼šç­‰å¾…è¯­éŸ³å¼€å§‹
                ring_buffer.append(frame)
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è§¦å‘æ¡ä»¶
                if is_speech:
                    triggered = True
                    silence_frames = 0
                    
                    # è¾“å‡ºç¼“å†²åŒºçš„å¸§ï¼ˆè¯­éŸ³å¼€å§‹å‰çš„å¡«å……ï¼‰
                    for buffered_frame in ring_buffer:
                        yield (buffered_frame, True, False)  # is_speech_start=True
                    
                    ring_buffer.clear()
            
            else:
                # å·²è§¦å‘çŠ¶æ€ï¼šæ”¶é›†è¯­éŸ³å¹¶æ£€æµ‹ç»“æŸ
                if is_speech:
                    silence_frames = 0
                else:
                    silence_frames += 1
                
                # æ£€æµ‹é™éŸ³æŒç»­æ—¶é—´
                if silence_frames >= self.num_silence_frames:
                    # è¯­éŸ³ç»“æŸ
                    yield (frame, False, True)  # is_speech_end=True
                    triggered = False
                    silence_frames = 0
                    ring_buffer.clear()
                else:
                    yield (frame, False, False)
    
    def extract_speech(
        self,
        audio_generator: Generator[bytes, None, None]
    ) -> Generator[bytes, None, None]:
        """
        æå–è¯­éŸ³ç‰‡æ®µï¼ˆå»é™¤é™éŸ³ï¼‰
        
        Args:
            audio_generator: éŸ³é¢‘å¸§ç”Ÿæˆå™¨
        
        Yields:
            å®Œæ•´çš„è¯­éŸ³ç‰‡æ®µ
        """
        ring_buffer = collections.deque(maxlen=self.num_pre_padding_frames)
        triggered = False
        voiced_frames = []
        silence_frames = 0
        
        for frame in audio_generator:
            if len(frame) != self.frame_bytes:
                continue
            
            is_speech = self.is_speech(frame)
            
            if not triggered:
                # æœªè§¦å‘çŠ¶æ€
                ring_buffer.append(frame)
                
                if is_speech:
                    triggered = True
                    logger.debug("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")
                    
                    # æ·»åŠ å¡«å……
                    for buffered_frame in ring_buffer:
                        voiced_frames.append(buffered_frame)
                    
                    ring_buffer.clear()
                    silence_frames = 0
            
            else:
                # å·²è§¦å‘çŠ¶æ€
                voiced_frames.append(frame)
                
                if is_speech:
                    silence_frames = 0
                else:
                    silence_frames += 1
                
                # æ£€æµ‹è¯­éŸ³ç»“æŸ
                if silence_frames >= self.num_silence_frames:
                    logger.debug("ğŸ”‡ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ")
                    
                    # æ·»åŠ åå¡«å……
                    for _ in range(self.num_post_padding_frames):
                        if len(ring_buffer) > 0:
                            voiced_frames.append(ring_buffer.popleft())
                    
                    # è¾“å‡ºå®Œæ•´çš„è¯­éŸ³ç‰‡æ®µ
                    yield b''.join(voiced_frames)
                    
                    # é‡ç½®
                    triggered = False
                    voiced_frames = []
                    ring_buffer.clear()
                    silence_frames = 0
        
        # å¤„ç†æœ€åçš„è¯­éŸ³ç‰‡æ®µ
        if voiced_frames:
            yield b''.join(voiced_frames)
    
    def filter_silence(self, audio_data: bytes) -> bytes:
        """
        æ‰¹é‡è¿‡æ»¤é™éŸ³ï¼ˆç”¨äºå·²å½•åˆ¶çš„éŸ³é¢‘ï¼‰
        
        Args:
            audio_data: å®Œæ•´éŸ³é¢‘æ•°æ®
        
        Returns:
            å»é™¤é™éŸ³åçš„éŸ³é¢‘æ•°æ®
        """
        frames = []
        offset = 0
        
        while offset + self.frame_bytes <= len(audio_data):
            frame = audio_data[offset:offset + self.frame_bytes]
            
            if self.is_speech(frame):
                frames.append(frame)
            
            offset += self.frame_bytes
        
        return b''.join(frames)
    
    def get_stats(self) -> dict:
        """
        è·å– VAD ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡å­—å…¸
        """
        return {
            'current_threshold': self.energy_threshold,
            'noise_energy': self.noise_energy,
            'auto_adjust': self.auto_adjust_threshold,
            'avg_energy': np.mean(list(self.energy_history)) if self.energy_history else 0
        }


