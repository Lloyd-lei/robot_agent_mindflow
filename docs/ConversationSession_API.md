# ConversationSession API æ–‡æ¡£

## ğŸ“¦ æ¦‚è¿°

`ConversationSession` æ˜¯ä¸€ä¸ªé«˜å±‚å°è£…çš„å¯¹è¯ä¼šè¯ç®¡ç†å™¨ï¼Œç”¨äºç»Ÿä¸€ç®¡ç† LLM + TTS çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸã€‚

**ä½ç½®**ï¼š`conversation_session.py`

**æ ¸å¿ƒåŠŸèƒ½**ï¼š
- ğŸ” è‡ªåŠ¨èµ„æºç®¡ç†ï¼ˆå¯åŠ¨/æ¸…ç†ï¼‰
- â±ï¸ è¶…æ—¶ä¿æŠ¤ï¼ˆé˜²æ­¢å¡æ­»ï¼‰
- ğŸ’¾ å¯¹è¯å†å²æŒä¹…åŒ–ï¼ˆæ”¯æŒä¼šè¯æ¢å¤ï¼‰
- ğŸ›¡ï¸ ç»Ÿä¸€å¼‚å¸¸å¤„ç†
- ğŸ“Š è¯¦ç»†æ—¥å¿—è¿½è¸ª

---

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„ç”¨æ³•

```python
from conversation_session import ConversationSession

# åˆ›å»ºå¹¶ä½¿ç”¨ä¼šè¯ï¼ˆè‡ªåŠ¨æ¸…ç†èµ„æºï¼‰
with ConversationSession() as session:
    result = session.chat("ä½ å¥½")
    print(result.response)
```

### å®Œæ•´é…ç½®

```python
with ConversationSession(
    llm_model="qwen2.5:3b",      # Ollama æ¨¡å‹
    tts_provider="edge",         # Edge TTS
    tts_voice="zh-CN-XiaoxiaoNeural",  # æ™“æ™“è¯­éŸ³
    enable_cache=True,           # å¯ç”¨ KV Cache
    show_reasoning=True,         # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
    timeout=120,                 # LLM æ¨ç†è¶…æ—¶ 2 åˆ†é’Ÿ
    tts_wait_timeout=180         # TTS æ’­æ”¾è¶…æ—¶ 3 åˆ†é’Ÿ
) as session:
    result = session.chat("è¯¦ç»†ä»‹ç»ä¸€ä¸‹ Google")
    print(f"å›å¤: {result.response}")
    print(f"è€—æ—¶: {result.duration:.2f}ç§’")
    print(f"å·¥å…·è°ƒç”¨: {result.tool_calls}æ¬¡")
```

---

## ğŸ“– API å‚è€ƒ

### æ„é€ å‡½æ•°

```python
ConversationSession(
    llm_provider: str = None,
    llm_model: str = None,
    tts_provider: str = "edge",
    tts_voice: str = None,
    enable_cache: bool = True,
    show_reasoning: bool = True,
    timeout: int = 60,
    tts_wait_timeout: int = 30
)
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `llm_provider` | `str` | `None` | LLM æä¾›å•†ï¼ˆè‡ªåŠ¨ä» config è¯»å–ï¼‰ |
| `llm_model` | `str` | `None` | æ¨¡å‹åç§°ï¼ˆå¦‚ `"qwen2.5:3b"`, `"gpt-4o-mini"`ï¼‰ |
| `tts_provider` | `str` | `"edge"` | TTS æä¾›å•†ï¼ˆ`"edge"` / `"azure"` / `"openai"`ï¼‰ |
| `tts_voice` | `str` | `None` | è¯­éŸ³åç§°ï¼ˆé»˜è®¤ï¼š`"zh-CN-XiaoxiaoNeural"`ï¼‰ |
| `enable_cache` | `bool` | `True` | å¯ç”¨ KV Cacheï¼ˆæå‡ 3-5 å€é€Ÿåº¦ï¼‰ |
| `show_reasoning` | `bool` | `True` | æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ï¼ˆå·¥å…·è°ƒç”¨æ—¥å¿—ï¼‰ |
| `timeout` | `int` | `60` | LLM æ¨ç†è¶…æ—¶ï¼ˆç§’ï¼‰ |
| `tts_wait_timeout` | `int` | `30` | TTS æ’­æ”¾è¶…æ—¶ï¼ˆç§’ï¼‰ |

#### è¶…æ—¶å‚æ•°å»ºè®®

| åœºæ™¯ | `timeout` | `tts_wait_timeout` |
|------|-----------|-------------------|
| Ollama qwen2.5:3b | 60-120s | 120-180s |
| Ollama qwen2.5:7b | 120-180s | 180-300s |
| OpenAI GPT-4 | 30-60s | 60-120s |
| é•¿å¯¹è¯/è®²æ•…äº‹ | 180-300s | 300-600s |

---

### æ ¸å¿ƒæ–¹æ³•

#### `start()` - å¯åŠ¨ä¼šè¯

```python
session.start() -> None
```

åˆå§‹åŒ– LLM å’Œ TTS èµ„æºã€‚

**æ³¨æ„**ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ—¶ä¼šè‡ªåŠ¨è°ƒç”¨ã€‚

#### `chat(user_input)` - å•è½®å¯¹è¯

```python
session.chat(user_input: str) -> SessionResult
```

æ‰§è¡Œå•è½®å¯¹è¯ï¼Œå¸¦è¶…æ—¶ä¿æŠ¤å’Œè‡ªåŠ¨ä¿å­˜å†å²ã€‚

**å‚æ•°**ï¼š
- `user_input` (`str`): ç”¨æˆ·è¾“å…¥æ–‡æœ¬

**è¿”å›**ï¼š`SessionResult`
```python
@dataclass
class SessionResult:
    response: str           # LLM å›å¤
    tool_calls: int         # å·¥å…·è°ƒç”¨æ¬¡æ•°
    duration: float         # è€—æ—¶ï¼ˆç§’ï¼‰
    should_end: bool        # æ˜¯å¦éœ€è¦ç»“æŸä¼šè¯
    streaming_stats: Dict   # TTS ç»Ÿè®¡ä¿¡æ¯
```

**æŠ›å‡ºå¼‚å¸¸**ï¼š
- `SessionNotStartedError`: ä¼šè¯æœªå¯åŠ¨
- `SessionTimeoutError`: å¯¹è¯è¶…æ—¶

**ç¤ºä¾‹**ï¼š
```python
with ConversationSession() as session:
    result = session.chat("ç°åœ¨å‡ ç‚¹ï¼Ÿ")
    print(result.response)       # "ç°åœ¨æ˜¯ä¸‹åˆ3ç‚¹15åˆ†"
    print(result.duration)       # 2.5
    print(result.tool_calls)     # 1 (è°ƒç”¨äº†æ—¶é—´å·¥å…·)
    print(result.should_end)     # False
```

#### `end()` - ç»“æŸä¼šè¯

```python
session.end() -> None
```

æ¸…ç†èµ„æºï¼ˆåœæ­¢ TTS ç®¡é“ï¼‰ã€‚

**æ³¨æ„**ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ—¶ä¼šè‡ªåŠ¨è°ƒç”¨ã€‚

---

### å¯¹è¯å†å²ç®¡ç†

#### `save_history()` - ä¿å­˜å¯¹è¯å†å²

```python
session.save_history(filepath: Optional[Path] = None) -> None
```

æ‰‹åŠ¨ä¿å­˜å¯¹è¯å†å²åˆ° JSON æ–‡ä»¶ã€‚

**å‚æ•°**ï¼š
- `filepath` (`Path`, å¯é€‰): ä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤ï¼š`sessions/session_TIMESTAMP.json`ï¼‰

**ç¤ºä¾‹**ï¼š
```python
session.save_history()  # ä¿å­˜åˆ°é»˜è®¤ä½ç½®
session.save_history(Path("backup/my_chat.json"))  # è‡ªå®šä¹‰è·¯å¾„
```

#### `load_history()` - åŠ è½½å¯¹è¯å†å²

```python
session.load_history(filepath: Optional[Path] = None) -> bool
```

ä»æ–‡ä»¶æ¢å¤å¯¹è¯å†å²ï¼ˆæ”¯æŒä¼šè¯æ¢å¤ï¼‰ã€‚

**å‚æ•°**ï¼š
- `filepath` (`Path`, å¯é€‰): æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šè‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„ä¼šè¯æ–‡ä»¶ï¼‰

**è¿”å›**ï¼š
- `True`: åŠ è½½æˆåŠŸ
- `False`: æ–‡ä»¶ä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥

**ç¤ºä¾‹**ï¼š
```python
with ConversationSession() as session:
    if session.load_history():
        print("âœ… å†å²å·²æ¢å¤")
    
    result = session.chat("æˆ‘ä¹‹å‰é—®è¿‡ä»€ä¹ˆï¼Ÿ")
```

#### `get_history_summary()` - è·å–å†å²æ‘˜è¦

```python
session.get_history_summary() -> Dict[str, Any]
```

è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯ã€‚

**è¿”å›**ï¼š
```python
{
    "session_id": "session_1234567890",
    "total_messages": 10,
    "turns": 5,
    "cache_enabled": True,
    "has_history_file": True
}
```

**ç¤ºä¾‹**ï¼š
```python
summary = session.get_history_summary()
print(f"å¯¹è¯è½®æ¬¡: {summary['turns']}")
print(f"æ¶ˆæ¯æ€»æ•°: {summary['total_messages']}")
```

#### `reset()` - é‡ç½®å¯¹è¯å†å²

```python
session.reset() -> None
```

æ¸…é™¤å¯¹è¯å†å²ï¼ˆä½†ä¿æŒèµ„æºï¼‰ã€‚

**ç¤ºä¾‹**ï¼š
```python
session.reset()
# ä¹‹åçš„å¯¹è¯ä¸ä¼šè®°å¾—ä¹‹å‰çš„å†…å®¹
```

---

### å±æ€§ï¼ˆåªè¯»ï¼‰

```python
session.is_started: bool          # ä¼šè¯æ˜¯å¦å·²å¯åŠ¨
session.session_id: str           # ä¼šè¯å”¯ä¸€ ID
```

---

## ğŸ”„ å®Œæ•´ä½¿ç”¨æµç¨‹

### æ‰‹åŠ¨ç®¡ç†æ¨¡å¼

```python
from conversation_session import ConversationSession

# 1. åˆ›å»ºä¼šè¯
session = ConversationSession(
    llm_model="qwen2.5:3b",
    timeout=120,
    tts_wait_timeout=180
)

# 2. å¯åŠ¨
session.start()

# 3. å¤šè½®å¯¹è¯
result1 = session.chat("æˆ‘å«å°æ˜")
result2 = session.chat("æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")  # âœ… è®°å¾—

# 4. æŸ¥çœ‹å†å²
summary = session.get_history_summary()
print(f"å¯¹è¯äº† {summary['turns']} è½®")

# 5. ç»“æŸ
session.end()
```

### ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¨¡å¼ï¼ˆæ¨èï¼‰

```python
with ConversationSession(llm_model="qwen2.5:3b") as session:
    # è‡ªåŠ¨è°ƒç”¨ start()
    
    result = session.chat("ä½ å¥½")
    print(result.response)
    
    # è‡ªåŠ¨è°ƒç”¨ end()
```

---

## ğŸ¨ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šåŸºç¡€å¯¹è¯

```python
with ConversationSession() as session:
    result = session.chat("ä½ å¥½")
    print(result.response)
```

### åœºæ™¯ 2ï¼šå¤šè½®å¯¹è¯ï¼ˆå¸¦è®°å¿†ï¼‰

```python
with ConversationSession(enable_cache=True) as session:
    session.chat("æˆ‘å–œæ¬¢ Python")
    session.chat("æˆ‘è®¨åŒ Java")
    
    result = session.chat("æˆ‘å–œæ¬¢ä»€ä¹ˆè¯­è¨€ï¼Ÿ")
    print(result.response)  # "ä½ å–œæ¬¢ Python" âœ…
```

### åœºæ™¯ 3ï¼šå¼‚å¸¸å¤„ç†

```python
from conversation_session import SessionTimeoutError

with ConversationSession(timeout=30) as session:
    try:
        result = session.chat("ç»™æˆ‘å†™ä¸€ä¸ªå¾ˆé•¿çš„æ•…äº‹")
    except SessionTimeoutError:
        print("è¶…æ—¶äº†ï¼Œä½†å¯¹è¯å†å²å·²ä¿å­˜")
        # å¯ä»¥ç»§ç»­å¯¹è¯
        result = session.chat("ç®€çŸ­ç‚¹")
```

### åœºæ™¯ 4ï¼šä¼šè¯æ¢å¤

```python
# ç¬¬ä¸€æ¬¡è¿è¡Œ
with ConversationSession() as session:
    session.chat("æˆ‘å–œæ¬¢ Rust")
    # è‡ªåŠ¨ä¿å­˜åˆ° sessions/session_XXX.json

# ç¨‹åºé‡å¯å
with ConversationSession() as session:
    if session.load_history():
        print("âœ… å†å²å·²æ¢å¤")
    
    result = session.chat("æˆ‘å–œæ¬¢ä»€ä¹ˆè¯­è¨€ï¼Ÿ")
    print(result.response)  # "ä½ å–œæ¬¢ Rust" âœ…
```

### åœºæ™¯ 5ï¼šé•¿å¯¹è¯ä¼˜åŒ–

```python
# é•¿å›å¤åœºæ™¯ï¼ˆå¦‚è®²æ•…äº‹ï¼‰
with ConversationSession(
    timeout=180,           # 3 åˆ†é’Ÿ LLM è¶…æ—¶
    tts_wait_timeout=300   # 5 åˆ†é’Ÿ TTS è¶…æ—¶
) as session:
    result = session.chat("ç»™æˆ‘è®²ä¸€ä¸ªé•¿ç¯‡æ•…äº‹")
    # âœ… ä¸ä¼šè¶…æ—¶
```

### åœºæ™¯ 6ï¼šç”Ÿäº§ç¯å¢ƒ

```python
# å…³é—­è°ƒè¯•ä¿¡æ¯
with ConversationSession(
    show_reasoning=False,  # ä¸æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
    enable_cache=True      # å¯ç”¨ç¼“å­˜
) as session:
    result = session.chat("ç”¨æˆ·é—®é¢˜")
    return result.response
```

---

## ğŸš¨ å¼‚å¸¸å¤„ç†

### å¼‚å¸¸ç±»å‹

```python
from conversation_session import (
    SessionNotStartedError,   # ä¼šè¯æœªå¯åŠ¨
    SessionTimeoutError        # å¯¹è¯è¶…æ—¶
)
```

### å®Œæ•´å¼‚å¸¸å¤„ç†

```python
with ConversationSession() as session:
    try:
        result = session.chat("ç”¨æˆ·è¾“å…¥")
        
    except SessionNotStartedError as e:
        print(f"ä¼šè¯æœªå¯åŠ¨: {e}")
        
    except SessionTimeoutError as e:
        print(f"è¶…æ—¶: {e}")
        # å¯¹è¯å†å²å·²è‡ªåŠ¨ä¿å­˜
        
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}")
```

---

## ğŸ“Š è¿”å›å€¼è¯¦è§£

### `SessionResult` ç»“æ„

```python
@dataclass
class SessionResult:
    response: str           # LLM çš„å›å¤æ–‡æœ¬
    tool_calls: int         # è°ƒç”¨äº†å‡ æ¬¡å·¥å…·
    duration: float         # æœ¬æ¬¡å¯¹è¯è€—æ—¶ï¼ˆç§’ï¼‰
    should_end: bool        # æ˜¯å¦æ£€æµ‹åˆ°å¯¹è¯ç»“æŸ
    streaming_stats: Dict   # TTS ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
```

### `streaming_stats` è¯¦è§£

```python
{
    "text_received": 10,      # æ¥æ”¶äº†å¤šå°‘æ®µæ–‡æœ¬
    "audio_generated": 10,    # ç”Ÿæˆäº†å¤šå°‘æ®µéŸ³é¢‘
    "audio_played": 10,       # æ’­æ”¾äº†å¤šå°‘æ®µéŸ³é¢‘
    "audio_failed": 0,        # å¤±è´¥äº†å¤šå°‘æ®µ
    "text_dropped": 0,        # èƒŒå‹ä¸¢å¼ƒäº†å¤šå°‘æ®µ
    "text_queue_size": 0,     # å½“å‰æ–‡æœ¬é˜Ÿåˆ—å¤§å°
    "audio_queue_size": 0,    # å½“å‰éŸ³é¢‘é˜Ÿåˆ—å¤§å°
    "active_tasks": 0,        # æ´»è·ƒä»»åŠ¡æ•°
    "is_playing": False       # æ˜¯å¦æ­£åœ¨æ’­æ”¾
}
```

---

## ğŸ”§ é…ç½®å»ºè®®

### Ollama qwen2.5:3bï¼ˆæ¨èï¼‰

```python
ConversationSession(
    llm_model="qwen2.5:3b",
    timeout=120,           # 2 åˆ†é’Ÿ
    tts_wait_timeout=180   # 3 åˆ†é’Ÿ
)
```

### Ollama qwen2.5:7bï¼ˆè´¨é‡æ›´å¥½ï¼‰

```python
ConversationSession(
    llm_model="qwen2.5:7b",
    timeout=180,           # 3 åˆ†é’Ÿ
    tts_wait_timeout=300   # 5 åˆ†é’Ÿ
)
```

### OpenAI GPT-4ï¼ˆé€Ÿåº¦å¿«ï¼‰

```python
ConversationSession(
    llm_model="gpt-4o-mini",
    timeout=60,            # 1 åˆ†é’Ÿ
    tts_wait_timeout=120   # 2 åˆ†é’Ÿ
)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. å§‹ç»ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
# âœ… æ¨è
with ConversationSession() as session:
    result = session.chat("ä½ å¥½")

# âŒ ä¸æ¨èï¼ˆéœ€è¦æ‰‹åŠ¨æ¸…ç†ï¼‰
session = ConversationSession()
session.start()
result = session.chat("ä½ å¥½")
session.end()
```

### 2. å¯ç”¨ç¼“å­˜ä»¥æ”¯æŒå†å²æ¢å¤

```python
# âœ… å¯ç”¨ç¼“å­˜ï¼ˆå¿…é¡»ï¼‰
ConversationSession(enable_cache=True)

# âŒ ç¦ç”¨ç¼“å­˜ï¼ˆæ— æ³•ä¿å­˜å†å²ï¼‰
ConversationSession(enable_cache=False)
```

### 3. æ ¹æ®åœºæ™¯è°ƒæ•´è¶…æ—¶

```python
# çŸ­å¯¹è¯
ConversationSession(timeout=60, tts_wait_timeout=120)

# é•¿å¯¹è¯
ConversationSession(timeout=180, tts_wait_timeout=300)
```

### 4. å¤„ç†è¶…æ—¶å¼‚å¸¸

```python
try:
    result = session.chat(user_input)
except SessionTimeoutError:
    # è¶…æ—¶æ—¶å†å²å·²ä¿å­˜ï¼Œå¯ä»¥ç»§ç»­å¯¹è¯
    print("è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç®€åŒ–é—®é¢˜")
```

### 5. å®šæœŸæ¸…ç†å†å²æ–‡ä»¶

```python
# sessions/ ç›®å½•ä¼šæŒç»­ç´¯ç§¯æ–‡ä»¶
# å»ºè®®å®šæœŸæ‰‹åŠ¨æ¸…ç†æ—§æ–‡ä»¶
```

---

## ğŸ› å·²çŸ¥é—®é¢˜

### 1. é•¿å›å¤ TTS è¶…æ—¶
**é—®é¢˜**ï¼š`tts_wait_timeout=30` å¤ªçŸ­ï¼Œé•¿å›å¤ä¼šè¢«å¼ºåˆ¶è·³è¿‡  
**è§£å†³**ï¼šå¢åŠ  `tts_wait_timeout` åˆ° 120-300 ç§’

### 2. `(END_CONVERSATION)` è¢«æ’­æ”¾
**é—®é¢˜**ï¼šç»“æŸå¯¹è¯æ—¶ä¼šå¬åˆ° "END CONVERSATION"  
**çŠ¶æ€**ï¼šå¾…ä¿®å¤

### 3. æ— æ³•ç¦ç”¨ TTS
**é—®é¢˜**ï¼šå³ä½¿ä¸éœ€è¦è¯­éŸ³ä¹Ÿä¼šåˆå§‹åŒ– TTS  
**çŠ¶æ€**ï¼šå¾…ä¼˜åŒ–

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [ä¼šè¯æŒä¹…åŒ–æŒ‡å—](SESSION_PERSISTENCE_GUIDE.md)
- [Ollama ä½¿ç”¨æŒ‡å—](Ollamaä½¿ç”¨æŒ‡å—.md)
- [é¡¹ç›® README](../README.md)

---

## ğŸ†• æ›´æ–°æ—¥å¿—

### v1.0.0 (2024-10-24)
- âœ… åˆå§‹ç‰ˆæœ¬
- âœ… æ”¯æŒ LLM + TTS å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†
- âœ… è¶…æ—¶ä¿æŠ¤æœºåˆ¶
- âœ… å¯¹è¯å†å²æŒä¹…åŒ–
- âœ… ä¼šè¯æ¢å¤åŠŸèƒ½
- âœ… è¯¦ç»†æ—¥å¿—è¿½è¸ª

---

**æœ€åæ›´æ–°**ï¼š2024-10-24  
**ä½œè€…**ï¼šAgent MVP Team

