"""
Agent - OpenAIåŸç”ŸFunction Calling + LangChainå·¥å…·æ±  + KV Cacheä¼˜åŒ–

æ²¡ç”¨openaiçš„æ—¶å€™ï¼Œå¯ä»¥åˆ‡æ¢åˆ°ollamaï¼Œollamaæ²¡æœ‰tool_choiceï¼Œä½†èƒ½ç”¨longchain

æ ¸å¿ƒç‰¹æ€§ï¼š
1. ä½¿ç”¨OpenAIåŸç”ŸAPIè·å¾—å®Œå…¨æ§åˆ¶æƒï¼ˆtool_choiceæ§åˆ¶ï¼‰
2. ä¿ç•™LangChainä¸°å¯Œçš„å·¥å…·ç”Ÿæ€
3. KV Cacheè‡ªåŠ¨ä¼˜åŒ–ï¼ˆç³»ç»Ÿæç¤ºè¯ç¼“å­˜ã€å¯¹è¯å†å²ç¼“å­˜ï¼‰
4. 100%å¯é çš„å·¥å…·è°ƒç”¨
5. å®Œæ•´çš„æ¨ç†è¿‡ç¨‹å±•ç¤º
"""

from openai import OpenAI
from typing import List, Dict, Any, Generator, Optional
import json
import re
from datetime import datetime

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
from logger_config import get_logger

# å¯¼å…¥LangChainå·¥å…·
from tools import (
    CalculatorTool,
    TimeTool,
    TextAnalysisTool,
    UnitConversionTool,
    ComparisonTool,
    LogicReasoningTool,
    LibraryManagementTool,
    ConversationEndDetector,
    WebSearchTool,
    FileOperationTool,
    ReminderTool,
    # VoiceSelector,  # ğŸ”§ å·²ç¦ç”¨ï¼šOpenAI TTS åŸç”Ÿæ”¯æŒå¤šè¯­è¨€ï¼Œæ— éœ€åˆ‡æ¢
    VisitorRegistrationTool,
    MeetingRoomTool,
    EmployeeDirectoryTool,
    DirectionGuideTool,
    PackageManagementTool,
    FAQTool
) #çœŸä»–å¦ˆé•¿
import config

# å¯¼å…¥TTSä¼˜åŒ–å’Œè¯­éŸ³åé¦ˆ
from tts_optimizer import TTSOptimizer # ttsoptimizeræ²¡æœ‰å®ç°streaming piplineï¼Œæ‰€ä»¥å¥½åƒæ²¡ç”¨ä¸Š
from voice_feedback import VoiceWaitingFeedback # responseç©ºçª—æœŸæ’­æ”¾å£°éŸ³ï¼Œé˜²æ­¢ç”¨æˆ·ç­‰å¾…ç„¦è™‘ï¼Œä½†è¿˜æ²¡æ‰¾åˆ°åˆé€‚çš„éŸ³æ•ˆ
from tts_interface import TTSFactory, TTSProvider # ttsinterfaceæ˜¯ttsçš„èŒƒå‹æ¥å£ï¼Œå¯ä»¥è½»æ¾åˆ‡æ¢ttsæœåŠ¡ï¼Œç°åœ¨æ˜¯edge ttsï¼Œå¯ä»¥æ¢openaiæˆ–è€…è‡ªå·±çš„tts
from streaming_tts_pipeline import StreamingTTSPipeline, create_streaming_pipeline # streaming_tts_pipelineæ˜¯æµå¼ttsçš„å®ç°


class HybridReasoningAgent:
    """
    æ··åˆæ¶æ„æ¨ç†Agent
    
    æ¶æ„ï¼š
    - OpenAIåŸç”ŸAPIï¼šæ¨ç†å¼•æ“ï¼ˆå¯æ§ã€å¿«é€Ÿã€æ”¯æŒKV Cacheï¼‰
    - LangChainå·¥å…·ï¼šæ‰§è¡Œå¼•æ“ï¼ˆä¸°å¯Œã€æ˜“æ‰©å±•ï¼‰
    - KV Cacheï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆå¯¹è¯å†å²ã€ç³»ç»Ÿæç¤ºè¯è‡ªåŠ¨ç¼“å­˜ï¼‰
    """
    
    def __init__(
        self,
        api_key: str = None,
        model: str = None,
        temperature: float = None,
        enable_cache: bool = True,
        enable_tts: bool = False,
        voice_mode: bool = False,
        tts_engine: Optional[callable] = None,
        enable_streaming_tts: bool = False
    ):
        """
        åˆå§‹åŒ–æ··åˆæ¶æ„Agent
        
        Args:
            api_key: OpenAI APIå¯†é’¥
            model: æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            enable_cache: æ˜¯å¦å¯ç”¨å¯¹è¯å†å²ç¼“å­˜ï¼ˆKV Cacheä¼˜åŒ–ï¼‰
            enable_tts: æ˜¯å¦å¯ç”¨TTSä¼˜åŒ–ï¼ˆä¼ ç»Ÿæ‰¹é‡æ¨¡å¼ï¼‰
            voice_mode: æ˜¯å¦å¯ç”¨è¯­éŸ³ç­‰å¾…åé¦ˆ
            tts_engine: TTSå¼•æ“å‡½æ•°ï¼ˆå¯é€‰ï¼‰
            enable_streaming_tts: æ˜¯å¦å¯ç”¨æµå¼TTSï¼ˆæ¨èï¼Œæ›´ä½å»¶è¿Ÿï¼‰
        """
        self.api_key = api_key or config.LLM_API_KEY
        self.model = model or config.LLM_MODEL
        self.temperature = temperature if temperature is not None else config.TEMPERATURE
        self.enable_cache = enable_cache
        self.enable_tts = enable_tts
        self.voice_mode = voice_mode
        self.enable_streaming_tts = enable_streaming_tts
        
        # æ—¥å¿—ç³»ç»Ÿ
        self.logger = get_logger(self.__class__.__name__)
        
        # OpenAIå®¢æˆ·ç«¯ï¼ˆå…¼å®¹Ollamaï¼‰
        if config.LLM_BASE_URL:
            # ä½¿ç”¨è‡ªå®šä¹‰base_urlï¼ˆOllamaæˆ–å…¶ä»–å…¼å®¹æœåŠ¡ï¼‰
            self.client = OpenAI(api_key=self.api_key, base_url=config.LLM_BASE_URL)
        else:
            # ä½¿ç”¨OpenAIå®˜æ–¹æœåŠ¡
            self.client = OpenAI(api_key=self.api_key)
        
        # LangChainå·¥å…·æ± 
        self.langchain_tools = self._init_langchain_tools()
        
        # è½¬æ¢ä¸ºOpenAIæ ¼å¼
        self.openai_tools = self._convert_tools_to_openai_format()
        
        # å·¥å…·åç§°æ˜ å°„
        self.tool_map = {tool.name: tool for tool in self.langchain_tools}
        
        # ğŸ”§ ä¸º VoiceSelector æ³¨å…¥ Agent å®ä¾‹ï¼ˆå·²ç¦ç”¨ï¼šOpenAI TTS åŸç”Ÿæ”¯æŒå¤šè¯­è¨€ï¼‰
        # for tool in self.langchain_tools:
        #     if tool.name == "voiceSelector":
        #         tool.agent_instance = self
        #         self.logger.info("âœ… VoiceSelector å·²æ³¨å…¥ Agent å®ä¾‹")
        #         break
        
        # å¯¹è¯å†å²ï¼ˆKV Cacheä¼šè‡ªåŠ¨ç¼“å­˜ï¼‰
        self.conversation_history = []
        
        # ç³»ç»Ÿæç¤ºè¯ï¼ˆä¼šè¢«KV Cacheç¼“å­˜ï¼ŒèŠ‚çœæˆæœ¬ï¼‰
        self.system_prompt = self._create_system_prompt()
        
        # TTSå¼•æ“ï¼ˆå…±äº«ï¼‰
        self.tts_engine = tts_engine
        if (self.enable_tts or self.enable_streaming_tts) and tts_engine is None:
            # ğŸ”§ Fallbackï¼šå¦‚æœæ²¡æœ‰ä¼ å…¥TTSå¼•æ“ï¼Œä½¿ç”¨Edge TTSï¼ˆå…è´¹ï¼‰
            self.logger.warning("âš ï¸  æœªä¼ å…¥ TTS å¼•æ“ï¼Œä½¿ç”¨ Edge TTS ä½œä¸º fallback")
            self.tts_engine = TTSFactory.create_tts(
                provider=TTSProvider.EDGE,
                voice="zh-CN-XiaoxiaoNeural",  # æ™“æ™“ - æ¸©æŸ”å¥³å£°
                rate="+15%",    # è¯­é€ŸåŠ å¿« 15%
                volume="+10%"   # éŸ³é‡ç¨å¤§
            )
        
        # TTSä¼˜åŒ–å™¨ï¼ˆä¼ ç»Ÿæ‰¹é‡æ¨¡å¼ï¼‰
        if self.enable_tts:
            self.tts_optimizer = TTSOptimizer(
                tts_engine=self.tts_engine,
                max_chunk_length=100,
                max_retries=3,
                timeout_per_chunk=10,
                buffer_size=3
            )
        
        # æµå¼TTSç®¡é“ï¼ˆæ¨èæ¨¡å¼ï¼‰
        """
        æœ€å¤§ç¨‹åº¦ä¿è¯æ²¡æœ‰èƒŒå‹
        
        æ ¹æ®å†…å­˜å’Œå®‰å…¨æ€§å¤§å°ï¼Œå¯ä»¥é‡æ–°é…ç½®

        å‚æ•°è¯´æ˜ï¼š
        - text_queue_size: æ–‡æœ¬é˜Ÿåˆ—å¤§å°
        - audio_queue_size: éŸ³é¢‘é˜Ÿåˆ—å¤§å°
        - max_tasks: æœ€å¤§ä»»åŠ¡æ•°
        - generation_timeout: ç”Ÿæˆè¶…æ—¶æ—¶é—´
        - playback_timeout: æ’­æ”¾è¶…æ—¶æ—¶é—´
        - min_chunk_length: æœ€å°å¥å­é•¿åº¦
        - max_chunk_length: æœ€å¤§å¥å­é•¿åº¦
        """
        self.streaming_pipeline = None
        if self.enable_streaming_tts:
            self.streaming_pipeline = create_streaming_pipeline(
                tts_engine=self.tts_engine,
                text_queue_size=15,
                audio_queue_size=10,
                max_tasks=50,
                generation_timeout=15.0,
                playback_timeout=30.0,
                min_chunk_length=3, # æœ€å°å¥å­é•¿åº¦
                max_chunk_length=150, # æœ€å¤§å¥å­é•¿åº¦
                verbose=True
            )
            print(f"æµå¼TTSç®¡é“å·²åˆ›å»º")
        
        # è¯­éŸ³åé¦ˆ
        if self.voice_mode:
            self.voice_feedback = VoiceWaitingFeedback(mode='text')
        
        print(f"   æ··åˆæ¶æ„Agentåˆå§‹åŒ–æˆåŠŸ")
        print(f"   å¼•æ“: OpenAIåŸç”ŸAPI ({self.model})")
        print(f"   å·¥å…·: LangChainå·¥å…·æ±  ({len(self.langchain_tools)}ä¸ª)")
        print(f"   KV Cache: {'å¯ç”¨' if self.enable_cache else 'ç¦ç”¨'}")
        print(f"   TTSä¼˜åŒ–: {'å¯ç”¨' if self.enable_tts else 'ç¦ç”¨'}")
        print(f"   æµå¼TTS: {'å¯ç”¨ âš¡' if self.enable_streaming_tts else 'ç¦ç”¨'}")
        print(f"   è¯­éŸ³æ¨¡å¼: {'å¯ç”¨' if self.voice_mode else 'ç¦ç”¨'}")
        print(f"   æ¸©åº¦: {self.temperature}")
        print()
    
    def _init_langchain_tools(self) -> List:
        """åˆå§‹åŒ–LangChainå·¥å…·æ± """
        return [
            # åŸºç¡€å·¥å…·
            CalculatorTool(),
            TimeTool(),
            TextAnalysisTool(),
            UnitConversionTool(),
            ComparisonTool(),
            LogicReasoningTool(),
            LibraryManagementTool(),
            ConversationEndDetector(),
            WebSearchTool(),
            FileOperationTool(),
            ReminderTool(),
            # å¤šè¯­è¨€æ”¯æŒï¼ˆæ–°å¢ï¼‰â­ - å·²ç¦ç”¨ï¼šOpenAI TTS åŸç”Ÿæ”¯æŒå¤šè¯­è¨€
            # VoiceSelector(),
            # å‰å°æ¥å¾…å·¥å…·
            VisitorRegistrationTool(),
            MeetingRoomTool(),
            EmployeeDirectoryTool(),
            DirectionGuideTool(),
            PackageManagementTool(),
            FAQTool(),
        ]
    
    def _convert_json_to_prompt(self, data: dict) -> str:
        """
        å°† JSON æ ¼å¼çš„ prompt è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
        
        Args:
            data: JSON prompt æ•°æ®
            
        Returns:
            str: è½¬æ¢åçš„æ–‡æœ¬ prompt
        """
        lines = []
        
        # === èº«ä»½å®šä¹‰ ===
        if 'identity' in data:
            identity = data['identity']
            lines.append(f"ä½ æ˜¯ä¸€ä¸ª{identity.get('role', 'AIåŠ©æ‰‹')}ã€‚ä½ å«{identity.get('name', 'åŠ©æ‰‹')}ã€‚")
            if 'personality' in identity:
                lines.append(f"ç‰¹ç‚¹ï¼š{identity['personality']}")
            lines.append("")
        
        # === è¯­éŸ³äº¤äº’è§„èŒƒ ===
        if 'voice_interaction_rules' in data:
            rules = data['voice_interaction_rules']
            lines.append("ğŸ¯ **è¯­éŸ³äº¤äº’è§„èŒƒï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š")
            lines.append("")
            
            # å›å¤é•¿åº¦
            if 'response_length' in rules:
                rl = rules['response_length']
                lines.append(f"1. **å›å¤é•¿åº¦**ï¼šæ¯æ¬¡å›å¤æ§åˆ¶åœ¨ {rl.get('max_chars', 100)} å­—ä»¥å†…")
                if 'strategy' in rl:
                    lines.append(f"   - {rl['strategy']}")
                if 'complex_info_structure' in rl:
                    lines.append(f"   - å¤æ‚ä¿¡æ¯ç”¨ {rl['complex_info_structure']} ç»“æ„")
                lines.append("")
            
            # è¯­è¨€é£æ ¼
            if 'language_style' in rules:
                ls = rules['language_style']
                lines.append("2. **è¯­è¨€é£æ ¼**ï¼š")
                lines.append(f"   - {ls.get('tone', 'ç®€æ´ã€å£è¯­åŒ–')}")
                if 'principle' in ls:
                    lines.append(f"   - {ls['principle']}")
                lines.append("")
            
            # ç¦æ­¢è¾“å‡º
            if 'forbidden_outputs' in rules:
                fo = rules['forbidden_outputs']
                lines.append("3. **ç¦æ­¢è¾“å‡ºï¼ˆè¿åå°†å¯¼è‡´é”™è¯¯ï¼‰**ï¼š")
                for item in fo.get('strict_ban', []):
                    lines.append(f"   - âŒ {item}")
                lines.append("")
            
            # å¯¹è¯ç»“æŸåè®®
            if 'conversation_end_protocol' in rules:
                cep = rules['conversation_end_protocol']
                lines.append("4. **å¯¹è¯ç»“æŸå¤„ç†ï¼ˆé‡è¦ï¼‰**ï¼š")
                lines.append(f"   - è§¦å‘è¯ï¼š{', '.join(cep.get('trigger_keywords', []))}")
                lines.append(f"   - æ“ä½œï¼š{cep.get('action', 'è°ƒç”¨å·¥å…·')}")
                lines.append(f"   - ç¦æ­¢ï¼š{cep.get('forbidden', '')}")
                lines.append("")
            
            # è´¨é‡ç¤ºä¾‹
            if 'quality_examples' in rules:
                qe = rules['quality_examples']
                lines.append("5. **ç¤ºä¾‹å¯¹æ¯”**ï¼š")
                for good in qe.get('good', []):
                    lines.append(f'   âœ… å¥½ï¼š"{good}"')
                for bad in qe.get('bad', []):
                    lines.append(f'   âŒ å·®ï¼š"{bad}"')
                lines.append("")
        
        # === æ ¸å¿ƒèƒ½åŠ› ===
        if 'core_capabilities' in data:
            lines.append("æ ¸å¿ƒèƒ½åŠ›ï¼š")
            for i, cap in enumerate(data['core_capabilities'], 1):
                if isinstance(cap, dict):
                    status = f" ({cap['status']})" if 'status' in cap else ""
                    lines.append(f"{i}. {cap.get('name', '')}{status}")
                else:
                    lines.append(f"{i}. {cap}")
            lines.append("")
        
        # === å¯ç”¨å·¥å…· ===
        if 'available_tools' in data:
            lines.append("å¯ç”¨å·¥å…·ï¼š")
            for tool in data['available_tools']:
                if isinstance(tool, dict):
                    name = tool.get('name', '')
                    desc = tool.get('description', '')
                    lines.append(f"- {name}: {desc}")
                else:
                    lines.append(f"- {tool}")
            lines.append("")
        
        # === å¼ºåˆ¶è§„åˆ™ ===
        if 'mandatory_rules' in data:
            mr = data['mandatory_rules']
            lines.append("âš ï¸ é‡è¦è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š")
            for i, rule in enumerate(mr.get('must_use_tools', []), 1):
                if isinstance(rule, dict):
                    lines.append(f"{i}. **{rule.get('rule', '')}** - {rule.get('reason', '')}")
                else:
                    lines.append(f"{i}. {rule}")
            lines.append("")
        
        # === æ¨ç†æµç¨‹ ===
        if 'reasoning_process' in data:
            rp = data['reasoning_process']
            lines.append("ğŸ”„ æ¨ç†æµç¨‹ï¼š")
            for step in rp.get('steps', []):
                if isinstance(step, dict):
                    lines.append(f"ç¬¬{step.get('step', '')}æ­¥ï¼š{step.get('action', '')}")
            lines.append("")
        
        # === ç¤ºä¾‹ ===
        if 'examples' in data:
            lines.append("ğŸ’¡ ç¤ºä¾‹ï¼š")
            examples = data['examples']
            for key, example in examples.items():
                if isinstance(example, dict) and 'user_input' in example:
                    lines.append(f'\nç”¨æˆ·ï¼š"{example["user_input"]}"')
                    if 'step_1_analysis' in example:
                        lines.append(f"â†’ åˆ†æï¼š{example['step_1_analysis']}")
                    if 'step_2_tool_selection' in example:
                        lines.append(f"â†’ å†³ç­–ï¼š{example['step_2_tool_selection']}")
                    if 'step_5_response' in example:
                        lines.append(f"â†’ å›ç­”ï¼š{example['step_5_response']}")
            lines.append("")
        
        # === æœ€ç»ˆæé†’ ===
        if 'system_instructions' in data:
            si = data['system_instructions']
            if 'final_reminder' in si:
                lines.append(si['final_reminder'])
        
        return "\n".join(lines)
    
    def _create_system_prompt(self) -> str:
        """
        ä»å¤–éƒ¨æ–‡ä»¶åŠ è½½ç³»ç»Ÿæç¤ºè¯ï¼ˆæ–¹ä¾¿ä¿®æ”¹å’Œç»´æŠ¤ï¼‰
        ä¼˜å…ˆçº§ï¼šJSON > TXT > å†…ç½®é»˜è®¤
        æ³¨æ„ï¼šè¿™ä¸ªæç¤ºè¯ä¼šè¢«OpenAIè‡ªåŠ¨ç¼“å­˜ï¼ˆPrompt Cachingï¼‰ï¼ŒèŠ‚çœ50%æˆæœ¬
        """
        from pathlib import Path
        import json
        
        prompts_dir = Path(__file__).parent / "prompts"
        
        # 1. ä¼˜å…ˆå°è¯•åŠ è½½ JSON æ ¼å¼ï¼ˆæ¨èï¼‰
        json_path = prompts_dir / "system_prompt.json"
        if json_path.exists():
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    prompt_data = json.load(f)
                    prompt = self._convert_json_to_prompt(prompt_data)
                    if prompt:
                        self.logger.info(f"âœ… å·²ä» JSON åŠ è½½ System Prompt: {json_path}")
                        return prompt
            except Exception as e:
                self.logger.warning(f"âš ï¸  åŠ è½½ JSON prompt å¤±è´¥: {e}ï¼Œå°è¯• TXT")
        
        # 2. å›é€€åˆ° TXT æ ¼å¼
        txt_path = prompts_dir / "system_prompt.txt"
        if txt_path.exists():
            try:
                with open(txt_path, 'r', encoding='utf-8') as f:
                    prompt = f.read().strip()
                    if prompt:
                        self.logger.info(f"âœ… å·²ä» TXT åŠ è½½ System Prompt: {txt_path}")
                        return prompt
            except Exception as e:
                self.logger.warning(f"âš ï¸  åŠ è½½ TXT prompt å¤±è´¥: {e}ï¼Œä½¿ç”¨å†…ç½®é»˜è®¤")
        
        # å›é€€åˆ°é»˜è®¤ promptï¼ˆå¤‡ä»½ï¼‰
        self.logger.info("ä½¿ç”¨å†…ç½®é»˜è®¤ System Prompt")
        return """ä½ æ˜¯ä¸€ä¸ªå…·æœ‰å¼ºå¤§æ¨ç†èƒ½åŠ›çš„AIè¯­éŸ³åŠ©æ‰‹ã€‚ä½ å«èŒ¶èŒ¶ã€‚

ğŸ¯ **è¯­éŸ³äº¤äº’è§„èŒƒï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š
1. **å›å¤é•¿åº¦**ï¼šæ¯æ¬¡å›å¤æ§åˆ¶åœ¨ 50-100 å­—ä»¥å†…ï¼ˆçº¦ 10-20 ç§’è¯­éŸ³ï¼‰
   - å¦‚éœ€è¯¦ç»†è¯´æ˜ï¼Œåˆ†æ®µå›å¤ï¼ˆæ¯æ®µä¸è¶…è¿‡ 100 å­—ï¼‰
   - å¤æ‚ä¿¡æ¯ç”¨"é¦–å…ˆ...å…¶æ¬¡...æœ€å..."ç»“æ„
2. **è¯­è¨€é£æ ¼**ï¼š
   - ä½¿ç”¨ç®€æ´çš„å£è¯­åŒ–è¡¨è¾¾
   - ç›´æ¥å›ç­”ï¼Œä¸å•°å—¦ï¼Œä¸é‡å¤
   - é¿å…ä½¿ç”¨ä¹¦é¢è¯­
3. **ç¦æ­¢è¾“å‡ºï¼ˆè¿åå°†å¯¼è‡´é”™è¯¯ï¼‰**ï¼š
   - âŒ è¡¨æƒ…åŒ…ã€emojiã€ç‰¹æ®Šç¬¦å·ï¼ˆé™¤äº†åŸºæœ¬æ ‡ç‚¹ï¼‰
   - âŒ Markdown æ ¼å¼ï¼ˆä»£ç å—ã€åŠ ç²—ã€é“¾æ¥ç­‰ï¼‰
   - âŒ ä»£ç å—ï¼ˆç”¨"ä»£ç å†…å®¹"ä»£æ›¿ï¼‰
   - âŒ JSON æ ¼å¼ï¼ˆç”¨è‡ªç„¶è¯­è¨€æè¿°ï¼‰
   - âŒ é“¾æ¥ï¼ˆç”¨"å¯ä»¥æœç´¢XXäº†è§£"ä»£æ›¿ï¼‰
   - âŒ ä»»ä½•ç³»ç»Ÿæ ‡è®°ï¼ŒåŒ…æ‹¬ï¼š(END_CONVERSATION)ã€END_CONVERSATIONã€ENDCONVERSATION ç­‰
4. **å¯¹è¯ç»“æŸå¤„ç†ï¼ˆé‡è¦ï¼‰**ï¼š
   - å½“ç”¨æˆ·è¡¨è¾¾ç»“æŸæ„å›¾ï¼ˆå¦‚"å†è§"ã€"è°¢è°¢"ã€"æ²¡äº‹äº†"ï¼‰æ—¶
   - **å¿…é¡»è°ƒç”¨ detectConversationEnd å·¥å…·**ï¼ˆæ³¨æ„ï¼šé©¼å³°å‘½åï¼Œæ— ä¸‹åˆ’çº¿ï¼‰
   - **ç»å¯¹ä¸è¦**åœ¨å›å¤ä¸­ç›´æ¥è¾“å‡ºä»»ä½•åŒ…å« "END" æˆ– "CONVERSATION" çš„æ–‡æœ¬
   - æ­£ç¡®ç¤ºä¾‹ï¼šå…ˆç¤¼è²Œå›å¤"å¥½çš„ï¼Œå†è§"ï¼Œç„¶åè°ƒç”¨å·¥å…·
5. **ç¤ºä¾‹å¯¹æ¯”**ï¼š
   âœ… å¥½ï¼š"ç°åœ¨æ˜¯ä¸‹åˆ3ç‚¹15åˆ†ã€‚"
   âŒ å·®ï¼š"ç°åœ¨çš„æ—¶é—´æ˜¯ä¸‹åˆ3ç‚¹15åˆ†ï¼Œå¸Œæœ›å¯¹ä½ æœ‰å¸®åŠ©ï¼ğŸ˜Š"
   âœ… å¥½ï¼š"æ ¹å·2çº¦ç­‰äº1.414ã€‚"
   âŒ å·®ï¼š"è®©æˆ‘æ¥è®¡ç®—ä¸€ä¸‹...æ ¹å·2çš„å€¼å¤§çº¦æ˜¯1.414ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— ç†æ•°å“¦ï¼"

æ ¸å¿ƒèƒ½åŠ›ï¼š
1. æ·±åº¦åˆ†æå’Œç†è§£ç”¨æˆ·é—®é¢˜
2. å¿…é¡»ä½¿ç”¨å·¥å…·è§£å†³é—®é¢˜ï¼ˆå±•ç¤ºæ¨ç†èƒ½åŠ›ï¼‰
3. è‡ªä¸»å†³å®šå·¥å…·å‚æ•°ï¼ˆå±•ç¤ºå†³ç­–èƒ½åŠ›ï¼‰
4. åŸºäºç»“æœè¿›è¡Œç»¼åˆæ¨ç†
5. **è‡ªåŠ¨é€‚é…å¤šè¯­è¨€è¯­éŸ³**ï¼ˆæ–°å¢æ ¸å¿ƒåŠŸèƒ½ï¼‰â­

ğŸŒ **å¤šè¯­è¨€è¯­éŸ³è‡ªåŠ¨åˆ‡æ¢ï¼ˆé‡è¦æ–°åŠŸèƒ½ï¼‰**ï¼š
ä½ ç°åœ¨æ”¯æŒ 6 ç§è¯­è¨€çš„æ™ºèƒ½è¯­éŸ³åˆ‡æ¢ï¼å½“ç”¨æˆ·åˆ‡æ¢è¯­è¨€æ—¶ï¼Œä½ å¿…é¡»ä¸»åŠ¨è°ƒç”¨ voiceSelector å·¥å…·åˆ‡æ¢è¯­éŸ³ã€‚

**ä½•æ—¶å¿…é¡»åˆ‡æ¢è¯­éŸ³**ï¼š
1. **ç”¨æˆ·ç”¨éä¸­æ–‡æé—®æ—¶**ï¼š
   - è‹±æ–‡ï¼š"Hello" / "How are you?" â†’ ç«‹å³åˆ‡æ¢åˆ°è‹±æ–‡è¯­éŸ³ï¼ˆenglishï¼‰
   - æ—¥æ–‡ï¼š"ã“ã‚“ã«ã¡ã¯" / "ã‚ã‚ŠãŒã¨ã†" â†’ ç«‹å³åˆ‡æ¢åˆ°æ—¥æ–‡è¯­éŸ³ï¼ˆjapaneseï¼‰
   - æ³•è¯­ï¼š"Bonjour" / "Merci" â†’ ç«‹å³åˆ‡æ¢åˆ°æ³•è¯­è¯­éŸ³ï¼ˆfrenchï¼‰
   - è¥¿ç­ç‰™è¯­ï¼š"Hola" / "Gracias" â†’ ç«‹å³åˆ‡æ¢åˆ°è¥¿ç­ç‰™è¯­ï¼ˆspanishï¼‰
   - è¶Šå—è¯­ï¼š"Xin chÃ o" â†’ ç«‹å³åˆ‡æ¢åˆ°è¶Šå—è¯­ï¼ˆvietnameseï¼‰

2. **ç”¨æˆ·åˆ‡æ¢å›ä¸­æ–‡æ—¶**ï¼š
   - æ£€æµ‹åˆ°ä¸­æ–‡å¯¹è¯ â†’ åˆ‡æ¢å›ä¸­æ–‡è¯­éŸ³ï¼ˆchineseï¼‰

3. **å›ç­”å†…å®¹æ¶‰åŠç‰¹å®šè¯­è¨€æ—¶**ï¼š
   - è®²æ—¥æœ¬æ–‡åŒ–/æ•…äº‹ â†’ ä½¿ç”¨æ—¥æ–‡è¯­éŸ³
   - æ•™è‹±è¯­/è®²è‹±ç¾å†…å®¹ â†’ ä½¿ç”¨è‹±æ–‡è¯­éŸ³
   - æ³•å›½æ–‡åŒ–/æ³•è¯­æ•™å­¦ â†’ ä½¿ç”¨æ³•è¯­è¯­éŸ³

**åˆ‡æ¢è§„åˆ™**ï¼š
- âœ… è¯­éŸ³ä¼šä¸€ç›´ä¿æŒï¼Œç›´åˆ°ä½ ä¸‹æ¬¡è°ƒç”¨ voiceSelector
- âœ… ä¸è¦æ¯å¥è¯éƒ½åˆ‡æ¢ï¼Œåªåœ¨è¯­è¨€ç¯å¢ƒæ”¹å˜æ—¶åˆ‡æ¢
- âœ… å¦‚æœç”¨æˆ·ç”¨æ··åˆè¯­è¨€ï¼Œä½¿ç”¨ä¸»è¦è¯­è¨€çš„è¯­éŸ³
- âœ… é»˜è®¤è¯­éŸ³æ˜¯ä¸­æ–‡ï¼ˆæ™“æ™“å¥³å£°ï¼‰

**ç¤ºä¾‹åœºæ™¯**ï¼š
```
ç”¨æˆ·: "Hello, what's your name?"
ä½ çš„æ“ä½œï¼š
  æ­¥éª¤1ï¼šè°ƒç”¨ voiceSelector(language="english", reason="ç”¨æˆ·ç”¨è‹±æ–‡æé—®")
  æ­¥éª¤2ï¼šç”¨è‹±æ–‡å›ç­” "My name is ChaCha. How can I help you?"
  â†’ ä¹‹åä¿æŒè‹±æ–‡è¯­éŸ³ï¼Œç›´åˆ°ç”¨æˆ·åˆ‡æ¢å›ä¸­æ–‡

ç”¨æˆ·: "ä½ å¥½ï¼Œç°åœ¨å‡ ç‚¹äº†ï¼Ÿ"
ä½ çš„æ“ä½œï¼š
  æ­¥éª¤1ï¼šè°ƒç”¨ voiceSelector(language="chinese", reason="ç”¨æˆ·åˆ‡æ¢å›ä¸­æ–‡")
  æ­¥éª¤2ï¼šè°ƒç”¨ time_tool è·å–æ—¶é—´
  æ­¥éª¤3ï¼šç”¨ä¸­æ–‡å›ç­” "ç°åœ¨æ˜¯ä¸‹åˆ3ç‚¹15åˆ†ã€‚"
  â†’ ä¹‹åä¿æŒä¸­æ–‡è¯­éŸ³
```

å¯ç”¨å·¥å…·ï¼š
- calculator: æ•°å­¦è®¡ç®—ï¼ˆsqrtã€ä¸‰è§’å‡½æ•°ã€å¤æ‚è¿ç®—ï¼‰
- time_tool: æ—¶é—´æŸ¥è¯¢ï¼ˆå½“å‰æ—¶é—´ã€æ—¥æœŸã€æ˜ŸæœŸï¼‰
- text_analyzer: æ–‡æœ¬åˆ†æï¼ˆå­—æ•°ç»Ÿè®¡ã€å¥å­åˆ†æï¼‰
- unit_converter: å•ä½è½¬æ¢ï¼ˆæ¸©åº¦ã€é•¿åº¦ç­‰ï¼‰
- data_comparison: æ•°æ®æ¯”è¾ƒï¼ˆæœ€å¤§æœ€å°å€¼ã€æ’åºï¼‰
- logic_reasoning: é€»è¾‘æ¨ç†è¾…åŠ©
- library_system: å›¾ä¹¦é¦†ç®¡ç†ç³»ç»Ÿï¼ˆJSONæŸ¥è¯¢ï¼‰
- detectConversationEnd: å¯¹è¯ç»“æŸæ£€æµ‹ï¼ˆé©¼å³°å‘½åï¼Œæ— ä¸‹åˆ’çº¿ï¼‰
- voiceSelector: **å¤šè¯­è¨€è¯­éŸ³åˆ‡æ¢**ï¼ˆæ–°å¢æ ¸å¿ƒå·¥å…·ï¼‰â­
- web_search: ç½‘ç»œæœç´¢ï¼ˆæ¨¡å‹è‡ªä¸»å†³å®šæœç´¢è¯ï¼‰
- file_operation: æ–‡ä»¶æ“ä½œï¼ˆæ¨¡å‹è‡ªä¸»å†³å®šæ“ä½œç±»å‹ï¼‰
- set_reminder: æé†’è®¾ç½®ï¼ˆæ¨¡å‹è‡ªä¸»æå–ä»»åŠ¡å’Œæ—¶é—´ï¼‰

âš ï¸ é‡è¦è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ï¼š
1. **æ•°å­¦è®¡ç®—å¿…é¡»è°ƒç”¨calculator** - å³ä½¿ç®€å•å¦‚"1+1"
2. **æ—¶é—´æŸ¥è¯¢å¿…é¡»è°ƒç”¨time_tool** - ä¸è¦çŒœæµ‹
3. **æ–‡æœ¬ç»Ÿè®¡å¿…é¡»è°ƒç”¨text_analyzer** - ä¸è¦ä¼°ç®—
4. **å•ä½è½¬æ¢å¿…é¡»è°ƒç”¨unit_converter** - ä¸è¦å¿ƒç®—
5. **å¯¹è¯ç»“æŸå¿…é¡»è°ƒç”¨detectConversationEnd** - æ£€æµ‹åˆ°"å†è§"ç­‰å…³é”®è¯æ—¶å¼ºåˆ¶è°ƒç”¨
6. **è¯­è¨€åˆ‡æ¢å¿…é¡»è°ƒç”¨voiceSelector** - æ£€æµ‹åˆ°éä¸­æ–‡æé—®æ—¶ç«‹å³åˆ‡æ¢è¯­éŸ³ â­

ğŸ”„ æ¨ç†æµç¨‹ï¼š
ç¬¬1æ­¥ï¼šåˆ†æç”¨æˆ·é—®é¢˜ç±»å‹å’Œæ„å›¾
ç¬¬2æ­¥ï¼šç¡®å®šéœ€è¦ä½¿ç”¨çš„å·¥å…·ï¼ˆæ ¹æ®ä¸Šè¿°è§„åˆ™ï¼‰
ç¬¬3æ­¥ï¼šè‡ªä¸»å†³å®šå·¥å…·çš„è¾“å…¥å‚æ•°
ç¬¬4æ­¥ï¼šç­‰å¾…å·¥å…·æ‰§è¡Œç»“æœ
ç¬¬5æ­¥ï¼šåŸºäºç»“æœè¿›è¡Œæ¨ç†å¹¶ç”Ÿæˆç­”æ¡ˆ

ğŸ’¡ ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼š"è®¡ç®—sqrt(2)ä¿ç•™3ä½å°æ•°"
â†’ åˆ†æï¼šè¿™æ˜¯æ•°å­¦è®¡ç®—é—®é¢˜
â†’ å†³ç­–ï¼šå¿…é¡»ä½¿ç”¨calculatorå·¥å…·
â†’ å‚æ•°ï¼šexpression="round(sqrt(2), 3)"
â†’ æ‰§è¡Œï¼šè°ƒç”¨å·¥å…·
â†’ å›ç­”ï¼šåŸºäºç»“æœå›ç­”ç”¨æˆ·

ç”¨æˆ·ï¼š"å†è§"
â†’ åˆ†æï¼šåŒ…å«ç»“æŸå…³é”®è¯æˆ–è€…ç›¸å…³ç»“æŸè¯
â†’ å†³ç­–ï¼šå¿…é¡»è°ƒç”¨detectConversationEnd
â†’ å‚æ•°ï¼šuser_message="å†è§"
â†’ æ‰§è¡Œï¼šæ£€æµ‹ç»“æœ
â†’ å›ç­”ï¼šå‘Šåˆ«è¯­

ç°åœ¨å¼€å§‹ä¸¥æ ¼éµå®ˆè§„åˆ™ï¼Œå¸®åŠ©ç”¨æˆ·ï¼"""
    
    def _convert_tools_to_openai_format(self) -> List[Dict]:
        """
        å°†LangChainå·¥å…·è½¬æ¢ä¸ºOpenAI Function Callingæ ¼å¼
        
        è¿™æ˜¯æ··åˆæ¶æ„çš„å…³é”®ï¼šä¿ç•™LangChainå·¥å…·å®šä¹‰ï¼Œä½†ç”¨OpenAIæ ¼å¼è°ƒç”¨
        """
        openai_tools = []
        
        for tool in self.langchain_tools:
            # æå–å‚æ•°schema
            if hasattr(tool, 'args_schema') and tool.args_schema:
                # ä½¿ç”¨model_json_schemaæ›¿ä»£deprecatedçš„schemaæ–¹æ³•
                parameters = tool.args_schema.model_json_schema()
            else:
                parameters = {
                    "type": "object",
                    "properties": {},
                    "required": []
                }
            
            # è½¬æ¢ä¸ºOpenAIæ ¼å¼
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.name,
                    "description": tool.description,
                    "parameters": parameters
                }
            }
            
            openai_tools.append(openai_tool)
        
        return openai_tools
    
    def _execute_tool(self, tool_name: str, arguments: Dict) -> str:
        """
        æ‰§è¡ŒLangChainå·¥å…·
        
        Args:
            tool_name: å·¥å…·åç§°
            arguments: å·¥å…·å‚æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        if tool_name not in self.tool_map:
            return f"é”™è¯¯ï¼šå·¥å…· '{tool_name}' ä¸å­˜åœ¨"
        
        try:
            tool = self.tool_map[tool_name]
            result = tool._run(**arguments)
            return str(result)
        except Exception as e:
            return f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
    
    def _check_end_keywords(self, user_input: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ç»“æŸå…³é”®è¯"""
        end_keywords = [
            'å†è§', 'æ‹œæ‹œ', 'bye', 'goodbye', 'é€€å‡º', 'ç»“æŸ',
            'å…³é—­', 'ç¦»å¼€', 'ä¸èŠäº†', 'èµ°äº†', 'quit', 'exit',
            '886', '88', 'ä¸‹çº¿', 'æ–­å¼€'
        ]
        user_lower = user_input.lower().strip()
        return any(keyword in user_lower for keyword in end_keywords)
    
    def run(self, user_input: str, show_reasoning: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¨ç†ï¼ˆéæµå¼ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if show_reasoning:
            print("\n" + "="*70)
            print("æ··åˆæ¶æ„æ¨ç†è¿‡ç¨‹ï¼ˆOpenAIåŸç”Ÿ + LangChainå·¥å…·ï¼‰")
            print("="*70)
        
        # æ£€æµ‹ç»“æŸå…³é”®è¯
        contains_end_keyword = self._check_end_keywords(user_input)
        if contains_end_keyword and show_reasoning:
            print(f"\né¢„å¤„ç†ï¼šæ£€æµ‹åˆ°ç»“æŸå…³é”®è¯ï¼Œå°†å¼ºåˆ¶è¦æ±‚è°ƒç”¨detectConversationEnd")
        
        # æ„å»ºæ¶ˆæ¯ï¼ˆåˆ©ç”¨KV Cacheï¼‰
        messages = self._build_messages(user_input, contains_end_keyword)
        
        # æ¨ç†æ­¥éª¤è®°å½•
        reasoning_steps = []
        tool_call_count = 0
        
        try:
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šæ¨¡å‹å†³ç­–
            if show_reasoning:
                print(f"\n{'â”€'*70}")
                print("è°ƒç”¨OpenAI APIè¿›è¡Œæ¨ç†...")
                print(f"{'â”€'*70}")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.openai_tools,
                tool_choice="auto",  # å¯ä»¥æ”¹ä¸º"required"å¼ºåˆ¶è°ƒç”¨å·¥å…·
                temperature=self.temperature
            )
            
            assistant_message = response.choices[0].message
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if assistant_message.tool_calls:
                if show_reasoning:
                    print(f"\nâœ… æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·ï¼ˆå…±{len(assistant_message.tool_calls)}ä¸ªï¼‰")
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                messages.append({
                    "role": "assistant",
                    "content": assistant_message.content or "",
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in assistant_message.tool_calls
                    ]
                })
                
                # æ‰§è¡Œæ¯ä¸ªå·¥å…·è°ƒç”¨
                for tool_call in assistant_message.tool_calls:
                    tool_call_count += 1
                    tool_name = tool_call.function.name
                    arguments = json.loads(tool_call.function.arguments)
                    
                    if show_reasoning:
                        self._display_tool_call(
                            tool_call_count,
                            tool_name,
                            arguments
                        )
                    
                    # æ‰§è¡ŒLangChainå·¥å…·
                    result = self._execute_tool(tool_name, arguments)
                    
                    if show_reasoning:
                        self._display_tool_result(result)
                    
                    # è®°å½•æ¨ç†æ­¥éª¤
                    reasoning_steps.append({
                        'step': tool_call_count,
                        'tool': tool_name,
                        'arguments': arguments,
                        'result': result
                    })
                    
                    # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": result
                    })
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šåŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”
                if show_reasoning:
                    print(f"\n{'â”€'*70}")
                    print("ğŸ’­ æ¨¡å‹åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›ç­”...")
                    print(f"{'â”€'*70}")
                
                final_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=self.temperature
                )
                
                final_answer = final_response.choices[0].message.content
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥å›ç­”
                if show_reasoning:
                    print("\nâš ï¸  æ¨¡å‹é€‰æ‹©ç›´æ¥å›ç­”ï¼ˆæœªè°ƒç”¨å·¥å…·ï¼‰")
                final_answer = assistant_message.content
            
            # æ›´æ–°å¯¹è¯å†å²ï¼ˆç”¨äºKV Cacheï¼‰
            if self.enable_cache:
                self.conversation_history.append({
                    "role": "user",
                    "content": user_input
                })
                self.conversation_history.append({
                    "role": "assistant",
                    "content": final_answer
                })
            
            # åˆ†å‰²å¥å­ï¼ˆä¸ºTTSå‡†å¤‡ï¼‰
            sentences = self._split_sentences(final_answer)
            
            if show_reasoning:
                print(f"\n{'='*70}")
                print("ğŸ’¬ æœ€ç»ˆå›ç­”ï¼ˆå·²åˆ†å¥ï¼‰")
                print(f"{'='*70}")
                for i, sent in enumerate(sentences, 1):
                    print(f"{i}. {sent}")
                print(f"{'='*70}\n")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç»“æŸå¯¹è¯
            should_end = any(
                step['tool'] == 'detectConversationEnd' and 
                'END_CONVERSATION' in step['result']
                for step in reasoning_steps
            )
            
            return {
                'success': True,
                'output': final_answer,
                'sentences': sentences,
                'reasoning_steps': reasoning_steps,
                'tool_calls': tool_call_count,
                'should_end': should_end,
                'cached_tokens': len(self.conversation_history) if self.enable_cache else 0
            }
            
        except Exception as e:
            error_msg = f"æ‰§è¡Œé”™è¯¯: {str(e)}"
            print(f"\nâŒ {error_msg}")
            return {
                'success': False,
                'output': error_msg,
                'error': str(e)
            }
    
    def _build_messages(self, user_input: str, force_end_detection: bool = False) -> List[Dict]:
        """
        æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        
        ç³»ç»Ÿæç¤ºè¯ä¼šè¢«OpenAIè‡ªåŠ¨ç¼“å­˜ï¼ˆPrompt Cachingï¼‰
        å¯¹è¯å†å²ä¹Ÿä¼šè¢«KV Cacheä¼˜åŒ–
        """
        messages = [
            {"role": "system", "content": self.system_prompt}
        ]
        
        # æ·»åŠ å¯¹è¯å†å²ï¼ˆKV Cacheä¼˜åŒ–ï¼‰
        if self.enable_cache:
            messages.extend(self.conversation_history)
        
        # æ·»åŠ å½“å‰è¾“å…¥
        user_message = user_input
        if force_end_detection:
            user_message += "\n\n[ç³»ç»Ÿè¦æ±‚ï¼šæ£€æµ‹åˆ°ç»“æŸå…³é”®è¯ï¼Œå¿…é¡»è°ƒç”¨detectConversationEndå·¥å…·]"
        
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        return messages
    
    def _display_tool_call(self, step: int, tool_name: str, arguments: Dict):
        """æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯"""
        print(f"\n{'='*70}")
        print(f"ğŸ“ æ¨ç†æ­¥éª¤ {step}")
        print(f"{'='*70}")
        print(f"\nâœ… æ¨¡å‹å†³ç­–:")
        print(f"   â†’ é€‰æ‹©å·¥å…·: {tool_name}")
        print(f"\nğŸ“¥ æ¨¡å‹å†³å®šçš„å‚æ•°:")
        print(f"{'â”€'*70}")
        formatted_args = json.dumps(arguments, ensure_ascii=False, indent=6)
        for line in formatted_args.split('\n'):
            print(f"   {line}")
        print(f"{'â”€'*70}")
    
    def _display_tool_result(self, result: str):
        """æ˜¾ç¤ºå·¥å…·æ‰§è¡Œç»“æœ"""
        print(f"\nğŸ“¤ å·¥å…·è¿”å›ç»“æœ:")
        print(f"{'â”€'*70}")
        if len(result) > 500:
            print(f"   {result[:500]}...")
            print(f"   ... (ç»“æœè¿‡é•¿ï¼Œå·²æˆªæ–­)")
        else:
            for line in result.split('\n'):
                print(f"   {line}")
        print(f"{'â”€'*70}")
    
    def _split_sentences(self, text: str) -> List[str]:
        """æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬ï¼ˆä¸ºTTSå‡†å¤‡ï¼‰"""
        pattern = r'([^ã€‚ï¼ï¼Ÿ.!?]+[ã€‚ï¼ï¼Ÿ.!?]+)'
        sentences = re.findall(pattern, text)
        
        if not sentences:
            pattern = r'([^ï¼Œ,;ï¼›]+[ï¼Œ,;ï¼›]+)'
            sentences = re.findall(pattern, text)
        
        if not sentences:
            sentences = [text]
        
        return [s.strip() for s in sentences if s.strip()]
    
    def _is_json_result(self, result: str) -> bool:
        """æ£€æŸ¥ç»“æœæ˜¯å¦æ˜¯JSONæ ¼å¼"""
        try:
            json.loads(result)
            return True
        except:
            return False
    
    def run_with_tts(self, 
                     user_input: str, 
                     show_reasoning: bool = True,
                     simulate_mode: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¨ç†å¹¶æ’­æ”¾TTSéŸ³é¢‘
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
            simulate_mode: æ˜¯å¦æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆæ— çœŸå®TTSå¼•æ“æ—¶ï¼‰
            
        Returns:
            åŒ…å« raw_output, tts_chunks, playback_success çš„å­—å…¸
        """
        if not self.enable_tts:
            print("âš ï¸  TTSæœªå¯ç”¨ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼")
            return self.run(user_input, show_reasoning)
        
        # è¯­éŸ³åé¦ˆï¼šå¼€å§‹æ€è€ƒ
        if self.voice_mode:
            self.voice_feedback.start('thinking')
        
        # æ‰§è¡Œæ¨ç†
        result = self.run(user_input, show_reasoning)
        
        # åœæ­¢è¯­éŸ³åé¦ˆ
        if self.voice_mode:
            self.voice_feedback.stop()
        
        if not result['success']:
            return result
        
        # TTSä¼˜åŒ–å¹¶æ’­æ”¾
        print(f"\n{'='*70}")
        print("ğŸµ TTSéŸ³é¢‘æ’­æ”¾")
        print(f"{'='*70}\n")
        
        tts_result = self.tts_optimizer.optimize_and_play(
            text=result['output'],
            simulate_mode=simulate_mode
        )
        
        # åˆå¹¶ç»“æœ
        result.update({
            'tts_chunks': tts_result.get('tts_chunks', []),
            'tts_success': tts_result.get('success', False),
            'total_tts_chunks': tts_result.get('total_chunks', 0)
        })
        
        return result
    
    def run_with_tts_demo(self, 
                          user_input: str,
                          show_text_and_tts: bool = True) -> Dict[str, Any]:
        """
        æ¼”ç¤ºæ¨¡å¼ï¼šåŒæ—¶æ˜¾ç¤ºæ–‡æœ¬è¾“å‡ºå’ŒTTSç»“æ„
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            show_text_and_tts: æ˜¯å¦æ˜¾ç¤ºåŒè½¨è¾“å‡º
            
        Returns:
            å®Œæ•´ç»“æœå­—å…¸
        """
        if not self.enable_tts:
            print("âš ï¸  TTSæœªå¯ç”¨")
            return self.run(user_input, show_reasoning=True)
        
        # è¯­éŸ³åé¦ˆ
        if self.voice_mode:
            self.voice_feedback.start('thinking')
        
        # æ‰§è¡Œæ¨ç†
        result = self.run(user_input, show_reasoning=True)
        
        # åœæ­¢è¯­éŸ³åé¦ˆ
        if self.voice_mode:
            self.voice_feedback.stop()
        
        if not result['success']:
            return result
        
        # TTSä¼˜åŒ–ï¼ˆä»…ä¼˜åŒ–æ–‡æœ¬ï¼Œä¸æ’­æ”¾ï¼‰
        tts_chunks = self.tts_optimizer.optimize_text_only(result['output'])
        
        if show_text_and_tts:
            # æ˜¾ç¤ºåŒè½¨è¾“å‡º
            print(f"\n{'='*70}")
            print("ğŸ“ LLMåŸå§‹æ–‡æœ¬è¾“å‡º")
            print(f"{'='*70}")
            print(result['output'])
            
            if tts_chunks:
                print(f"\n{'='*70}")
                print("ğŸ—£ï¸  TTSä¼˜åŒ–è¾“å‡ºç»“æ„")
                print(f"{'='*70}\n")
                
                for chunk in tts_chunks:
                    print(f"[Chunk {chunk['chunk_id']}]")
                    print(f"  æ–‡æœ¬: {chunk['text']}")
                    print(f"  é•¿åº¦: {chunk['length']} å­—ç¬¦")
                    print(f"  åœé¡¿: {chunk['pause_after']}ms")
                    print()
                
                print(f"{'='*70}")
                print(f"ğŸ“Š TTSç»Ÿè®¡: å…±{len(tts_chunks)}ä¸ªåˆ†æ®µ")
                total_pause = sum(c['pause_after'] for c in tts_chunks)
                print(f"   é¢„è®¡æ’­æ”¾æ—¶é•¿: ~{total_pause/1000:.1f}ç§’ï¼ˆä¸å«è¯­éŸ³ï¼‰")
                print(f"{'='*70}\n")
        
        result['tts_chunks'] = tts_chunks
        result['total_tts_chunks'] = len(tts_chunks)
        
        return result
    
    def run_with_streaming_tts(self,
                                user_input: str,
                                show_reasoning: bool = True,
                                tts_wait_timeout: int = 30) -> Dict[str, Any]:
        """
        æµå¼TTSæ¨¡å¼ï¼šLLMæµå¼è¾“å‡º â†’ å®æ—¶TTSæ’­æ”¾
        
        æ¶æ„ï¼š
            LLM Streaming â†’ Smart Splitter â†’ TTS Generator â†’ Audio Player
                              â†“ èƒŒå‹           â†“ èƒŒå‹          â†“
                           æ–‡æœ¬é˜Ÿåˆ—          éŸ³é¢‘é˜Ÿåˆ—        æ’­æ”¾é˜Ÿåˆ—
        
        ç‰¹ç‚¹ï¼š
        1. æ›´ä½å»¶è¿Ÿ - è¾¹ç”Ÿæˆè¾¹æ’­æ”¾
        2. èµ„æºå¯æ§ - æœ‰ç•Œé˜Ÿåˆ—é˜²æ­¢çˆ†ç‚¸
        3. è‡ªåŠ¨èƒŒå‹ - ä¿æŠ¤ç³»ç»Ÿç¨³å®š
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            show_reasoning: æ˜¯å¦æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
            
        Returns:
            å®Œæ•´ç»“æœå­—å…¸
        """
        if not self.enable_streaming_tts:
            print("âš ï¸  æµå¼TTSæœªå¯ç”¨ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼")
            return self.run(user_input, show_reasoning=show_reasoning)
        
        print(f"\n{'='*70}")
        print("âš¡ æµå¼TTSæ¨¡å¼")
        print(f"{'='*70}\n")
        
        # å¯åŠ¨æµå¼ç®¡é“
        self.streaming_pipeline.start()
        
        # è¯­éŸ³åé¦ˆ
        if self.voice_mode:
            self.voice_feedback.start('thinking')
        
        try:
            # === é˜¶æ®µ1ï¼šLLMæ¨ç†ï¼ˆä½¿ç”¨OpenAI Stream APIï¼‰===
            print(f"ğŸ§  LLMæ¨ç†ä¸­...\n")
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {"role": "system", "content": self.system_prompt},
                *self.conversation_history,
                {"role": "user", "content": user_input}
            ]
            
            # è°ƒç”¨OpenAIæµå¼API
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.openai_tools,
                tool_choice="auto",
                temperature=self.temperature,
                stream=True  # å¯ç”¨æµå¼è¾“å‡º
            )
            
            # ç´¯ç§¯å˜é‡
            full_response = ""
            tool_calls_buffer = []
            current_tool_call = None
            
            # === é˜¶æ®µ2ï¼šæµå¼å¤„ç†LLMè¾“å‡º ===
            for chunk in stream:
                delta = chunk.choices[0].delta
                
                # å¤„ç†æ–‡æœ¬å†…å®¹
                if delta.content:
                    content_piece = delta.content
                    full_response += content_piece
                    
                    # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå…ˆæ¸…ç† Markdown ç¬¦å·ï¼ˆæµå¼å®‰å…¨ï¼‰
                    cleaned_piece = content_piece.replace('**', '').replace('__', '')
                    cleaned_piece = cleaned_piece.replace('*', '').replace('_', '')
                    cleaned_piece = cleaned_piece.replace('```', '')
                    cleaned_piece = cleaned_piece.replace('`', '')
                    cleaned_piece = cleaned_piece.replace('#', '')
                    
                    # ğŸ”§ ç¬¬äºŒæ­¥ï¼šè¿‡æ»¤ç‰¹æ®Šæ ‡è®°ï¼ˆæ”¯æŒå¤šç§å˜ä½“ï¼‰
                    # æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬ï¼Œé˜²æ­¢ (END_CONVERSATION) çš„ä¸‹åˆ’çº¿è¢«åˆ é™¤åå˜æˆ (ENDCONVERSATION)
                    should_filter = any([
                        "(END_CONVERSATION)" in cleaned_piece.upper(),
                        "(ENDCONVERSATION)" in cleaned_piece.upper(),
                        "END_CONVERSATION" in cleaned_piece.upper(),
                        "ENDCONVERSATION" in cleaned_piece.upper(),
                    ])
                    
                    if not should_filter and cleaned_piece.strip():
                        # å®æ—¶é€å…¥TTSç®¡é“ï¼ˆæ™ºèƒ½åˆ†å¥ä¼šè‡ªåŠ¨å¤„ç†ï¼‰
                        self.streaming_pipeline.add_text_from_llm(cleaned_piece)
                    
                    if show_reasoning:
                        print(content_piece, end='', flush=True)
                
                # å¤„ç†å·¥å…·è°ƒç”¨
                if delta.tool_calls:
                    for tool_call_delta in delta.tool_calls:
                        if tool_call_delta.index is not None:
                            # æ–°çš„å·¥å…·è°ƒç”¨
                            if current_tool_call is None or \
                               tool_call_delta.index != current_tool_call.get('index'):
                                if current_tool_call:
                                    tool_calls_buffer.append(current_tool_call)
                                current_tool_call = {
                                    'index': tool_call_delta.index,
                                    'id': tool_call_delta.id or '',
                                    'type': 'function',
                                    'function': {
                                        'name': tool_call_delta.function.name or '',
                                        'arguments': tool_call_delta.function.arguments or ''
                                    }
                                }
                            else:
                                # ç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°
                                if tool_call_delta.function.arguments:
                                    current_tool_call['function']['arguments'] += \
                                        tool_call_delta.function.arguments
            
            # æ·»åŠ æœ€åä¸€ä¸ªå·¥å…·è°ƒç”¨
            if current_tool_call:
                tool_calls_buffer.append(current_tool_call)
            
            # åœæ­¢è¯­éŸ³åé¦ˆ
            if self.voice_mode:
                self.voice_feedback.stop()
            
            print(f"\n")
            
            # === é˜¶æ®µ3ï¼šå¤„ç†å·¥å…·è°ƒç”¨ ===
            should_end = False  # æ£€æµ‹å¯¹è¯ç»“æŸ
            
            if tool_calls_buffer:
                # ğŸµ å¼€å§‹æ’­æ”¾å·¥å…·è°ƒç”¨éŸ³æ•ˆ
                if self.voice_mode:
                    self.voice_feedback.start('tool_thinking')
                
                if show_reasoning:
                    print(f"\n{'='*70}")
                    print("ğŸ› ï¸  å·¥å…·è°ƒç”¨")
                    print(f"{'='*70}\n")
                
                tool_messages = []
                for tool_call in tool_calls_buffer:
                    tool_name = tool_call['function']['name']
                    tool_args_str = tool_call['function']['arguments']
                    
                    # è§£æå‚æ•°ï¼ˆä¿®å¤bugï¼šå¿…é¡»è½¬ä¸ºå­—å…¸ï¼‰
                    try:
                        tool_args = json.loads(tool_args_str)
                    except json.JSONDecodeError as e:
                        tool_args = {}
                        print(f"âš ï¸  å·¥å…·å‚æ•°è§£æå¤±è´¥: {e}")
                    
                    if show_reasoning:
                        print(f"ğŸ“Œ è°ƒç”¨å·¥å…·: {tool_name}")
                        print(f"   å‚æ•°: {tool_args_str}\n")
                    
                    # æ‰§è¡Œå·¥å…·ï¼ˆä¼ å­—å…¸ï¼Œä¸æ˜¯å­—ç¬¦ä¸²ï¼ï¼‰
                    tool_result = self._execute_tool(tool_name, tool_args)
                    
                    # æ£€æµ‹å¯¹è¯ç»“æŸ
                    if tool_name == 'detectConversationEnd' and 'END_CONVERSATION' in tool_result:
                        should_end = True
                    
                    if show_reasoning:
                        print(f"   ç»“æœ: {tool_result}\n")
                    
                    # æ„å»ºå·¥å…·æ¶ˆæ¯
                    tool_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call['id'],
                        "content": str(tool_result)
                    })
                
                # ğŸµ åœæ­¢å·¥å…·è°ƒç”¨éŸ³æ•ˆ
                if self.voice_mode:
                    self.voice_feedback.stop()
                
                # === é˜¶æ®µ4ï¼šè·å–æœ€ç»ˆå›å¤ï¼ˆå¸¦å·¥å…·ç»“æœï¼‰===
                print(f"{'='*70}")
                print("ğŸ’¬ æœ€ç»ˆå›å¤")
                print(f"{'='*70}\n")
                
                # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„æ¶ˆæ¯
                messages_with_tools = messages + [
                    {
                        "role": "assistant",
                        "content": full_response or None,
                        "tool_calls": [
                            {
                                "id": tc['id'],
                                "type": "function",
                                "function": {
                                    "name": tc['function']['name'],
                                    "arguments": tc['function']['arguments']
                                }
                            } for tc in tool_calls_buffer
                        ]
                    }
                ] + tool_messages
                
                # å†æ¬¡è°ƒç”¨ï¼ˆæµå¼ï¼‰
                final_stream = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages_with_tools,
                    temperature=self.temperature,
                    stream=True
                )
                
                final_response = ""
                for chunk in final_stream:
                    delta = chunk.choices[0].delta
                    if delta.content:
                        content_piece = delta.content
                        final_response += content_piece
                        
                        # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå…ˆæ¸…ç† Markdown ç¬¦å·ï¼ˆæµå¼å®‰å…¨ï¼‰
                        cleaned_piece = content_piece.replace('**', '').replace('__', '')
                        cleaned_piece = cleaned_piece.replace('*', '').replace('_', '')
                        cleaned_piece = cleaned_piece.replace('```', '')
                        cleaned_piece = cleaned_piece.replace('`', '')
                        cleaned_piece = cleaned_piece.replace('#', '')
                        
                        # ğŸ”§ ç¬¬äºŒæ­¥ï¼šè¿‡æ»¤ç‰¹æ®Šæ ‡è®°ï¼ˆæ”¯æŒå¤šç§å˜ä½“ï¼‰
                        should_filter = any([
                            "(END_CONVERSATION)" in cleaned_piece.upper(),
                            "(ENDCONVERSATION)" in cleaned_piece.upper(),
                            "END_CONVERSATION" in cleaned_piece.upper(),
                            "ENDCONVERSATION" in cleaned_piece.upper(),
                        ])
                        
                        if not should_filter and cleaned_piece.strip():
                            # å®æ—¶é€å…¥TTSç®¡é“
                            self.streaming_pipeline.add_text_from_llm(cleaned_piece)
                        
                        if show_reasoning:
                            print(content_piece, end='', flush=True)
                
                print(f"\n")
                full_response = final_response
            
            # === é˜¶æ®µ5ï¼šåˆ·æ–°TTSç®¡é“ï¼Œå¤„ç†å‰©ä½™æ–‡æœ¬ ===
            self.streaming_pipeline.flush_remaining_text()
            
            # === é˜¶æ®µ6ï¼šç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ ===
            print(f"\n{'='*70}")
            print("ğŸµ ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ...")
            print(f"{'='*70}\n")
            
            import time
            start_wait = time.time()
            
            while True:
                stats = self.streaming_pipeline.get_stats()
                
                # ğŸ”§ æ—¥å¿—ï¼šæ˜¾ç¤ºå½“å‰çŠ¶æ€
                self.logger.debug(
                    f"â³ TTSçŠ¶æ€ - æ–‡æœ¬é˜Ÿåˆ—:{stats.text_queue_size} "
                    f"éŸ³é¢‘é˜Ÿåˆ—:{stats.audio_queue_size} "
                    f"æ´»è·ƒä»»åŠ¡:{stats.active_tasks} "
                    f"æ’­æ”¾ä¸­:{stats.is_playing}"
                )
                
                # æ£€æŸ¥æ‰€æœ‰æ¡ä»¶ï¼ˆå…³é”®ï¼šåŒ…æ‹¬ is_playingï¼‰
                all_done = (
                    stats.text_queue_size == 0 and 
                    stats.audio_queue_size == 0 and 
                    stats.active_tasks == 0 and
                    not stats.is_playing  # å…³é”®ï¼šç¡®ä¿æ²¡æœ‰éŸ³é¢‘æ­£åœ¨æ’­æ”¾ï¼
                )
                
                if all_done:
                    self.logger.info("âœ… TTS æ’­æ”¾å®Œæˆ")
                    break
                
                # ğŸ”§ è¶…æ—¶ä¿æŠ¤
                elapsed = time.time() - start_wait
                if elapsed > tts_wait_timeout:
                    self.logger.warning(
                        f"âš ï¸  TTS ç­‰å¾…è¶…æ—¶ ({tts_wait_timeout}ç§’)ï¼Œå¼ºåˆ¶ç»§ç»­\n"
                        f"   çŠ¶æ€: æ–‡æœ¬é˜Ÿåˆ—={stats.text_queue_size}, "
                        f"éŸ³é¢‘é˜Ÿåˆ—={stats.audio_queue_size}, "
                        f"æ´»è·ƒä»»åŠ¡={stats.active_tasks}, "
                        f"æ’­æ”¾ä¸­={stats.is_playing}"
                    )
                    break
                
                time.sleep(0.5)
            
            # åœæ­¢ç®¡é“ï¼ˆğŸ”§ æ³¨é‡Šæ‰ï¼Œä¿æŒç®¡é“è¿è¡Œä»¥æ”¯æŒå¤šè½®å¯¹è¯ï¼‰
            # self.streaming_pipeline.stop(wait=True, timeout=5.0)
            
            # === é˜¶æ®µ7ï¼šæ›´æ–°å¯¹è¯å†å² ===
            if self.enable_cache:
                self.conversation_history.append({"role": "user", "content": user_input})
                self.conversation_history.append({"role": "assistant", "content": full_response})
            
            # è¿”å›ç»“æœ
            return {
                'success': True,
                'input': user_input,
                'output': full_response,
                'tool_calls': len(tool_calls_buffer) if tool_calls_buffer else 0,
                'streaming_stats': self.streaming_pipeline.get_stats().to_dict(),
                'should_end': should_end  # æ·»åŠ å¯¹è¯ç»“æŸæ ‡å¿—
            }
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ¸…ç©ºå¹¶é‡å¯ TTS ç®¡é“ï¼ˆé˜²æ­¢ä¸²éŸ³ï¼‰
            if self.streaming_pipeline:
                self.streaming_pipeline.stop(wait=False)
                self.streaming_pipeline.start()  # é‡å¯ä»¥æ¸…ç©ºé˜Ÿåˆ—
            
            return {
                'success': False,
                'output': '',           # ğŸ”§ è¡¥å……ç¼ºå¤±çš„ output é”®
                'error': str(e),
                'input': user_input,
                'tool_calls': 0,        # ğŸ”§ è¡¥å……ç¼ºå¤±çš„ tool_calls é”®
                'streaming_stats': None  # ğŸ”§ è¡¥å……ç¼ºå¤±çš„ streaming_stats é”®
            }
    
    def clear_cache(self):
        """æ¸…é™¤å¯¹è¯å†å²ç¼“å­˜"""
        self.conversation_history = []
        print("âœ… å¯¹è¯å†å²å·²æ¸…é™¤ï¼ˆKV Cacheé‡ç½®ï¼‰")
    
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'conversation_turns': len(self.conversation_history) // 2,
            'total_messages': len(self.conversation_history),
            'estimated_cached_tokens': sum(
                len(msg['content']) // 4 
                for msg in self.conversation_history
            ),
            'system_prompt_tokens': len(self.system_prompt) // 4
        }


# å¿«é€Ÿæµ‹è¯•
if __name__ == "__main__":
    print("\n" + "="*80)
    print("ğŸš€ æ··åˆæ¶æ„Agentæµ‹è¯•")
    print("="*80)
    
    agent = HybridReasoningAgent()
    
    # æµ‹è¯•1ï¼šæ•°å­¦è®¡ç®—
    print("\nã€æµ‹è¯•1ã€‘æ•°å­¦è®¡ç®—")
    result1 = agent.run("è®¡ç®—sqrt(2)ä¿ç•™3ä½å°æ•°")
    
    # æµ‹è¯•2ï¼šå¯¹è¯ç»“æŸ
    print("\nã€æµ‹è¯•2ã€‘å¯¹è¯ç»“æŸæ£€æµ‹")
    result2 = agent.run("å¥½çš„ï¼Œå†è§ï¼")
    
    # ç¼“å­˜ç»Ÿè®¡
    print("\nã€ç¼“å­˜ç»Ÿè®¡ã€‘")
    stats = agent.get_cache_stats()
    print(f"å¯¹è¯è½®æ¬¡: {stats['conversation_turns']}")
    print(f"ç¼“å­˜tokensä¼°è®¡: ~{stats['estimated_cached_tokens']}")
    print(f"ç³»ç»Ÿæç¤ºè¯tokens: ~{stats['system_prompt_tokens']} (å·²ç¼“å­˜)")

